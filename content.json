{"pages":[{"title":"about","text":"About Me 1995/男 软工硕士（在读） 摩羯座 篮球 - 健身 - 旅行 心怀远方 不安于现状的半理想主义者 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/about/index.html"},{"title":"archives","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/archives/index.html"},{"title":"tags","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/tags/index.html"},{"title":"categories","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/categories/index.html"}],"posts":[{"title":"001职业的天花板来自认识的局限性","text":"职业的天花板来自认识的局限性计算机思维计算机思维是全方位的，不太可能用一两句来概括。简单地讲，需要处理好这样七对关系： 大和小 生活在今天的人依然对于大数的认知是无感的。换一个角度这也说明了人对于“大”和“小”这两个概念的理解其实受限于具体生活的环境。你习惯了某一个环境的度量，其实很难理解在量级上大得多的世界。 快和慢 人的进化相对于计算机的发展就是很慢的，计算机的发展遵循“摩尔定律”，在智能时代，人的思维要适应这种快速变化。 多维度和单一维度 从总体上看，人脑是线性处理事务的，看问题常常是一个角度，也没有能力把很多角度综合起来。但是，计算机有这个能力，因此占到了多维度的便宜。 网络和个体 人的思维的个体行为，作决定彼此不干扰。这有好的一面，但是也难以集中很多人的智慧，产生叠加的效果。事实上，群体智慧的简单叠加甚至不如个人智慧。但是人工智能是建立在网络效应基础上的，它是通过很多彼此联系的计算机共同协作工作而产生的。 自顶向下和自底向上 自顶向下做事这一点是计算机的精髓，而人更适应自底向上。在一个组织内，自底向上的做事方式更加容易激发群体的积极性，但是容易造成资源的浪费。 全局和局部 人做事情时，限于自己的认知，通常得到的是局部最佳，失去对全局的优化的可能性。由于计算机有处理大数的能力，以及是自顶向下的做事方式，更加容易得到全局最优。 成本和表现 人很多时候喜欢强调对错，喜欢追求绝对的公平，喜欢要求最好的结果。但是，从工程的角度讲，好和坏，只是在固定成本下相对的表现。计算机里面无论是软件设计，还是硬件设计，都是平衡性能和成本的关系。 此外，掌握计算机思维，还需要理解下面两个原则： 一. 等价性原则 很多时候，一个较难的问题A和相对容易的问题B是等价的。但是人类常常容易给什么问题就解决什么问题，给了A就解决A，尽管它很难。而计算机则会试图解决等价，但是却更简单的问题。 二.模块化原则 我们在生活中，做一个桌子，或者一个椅子，会直接去做。而在计算机的世界里，永远是先制作几个非常简单，能够大量复制的乐高积木块，然后用很多这样简单的模块，搭出复杂的桌子和椅子。 计算机思维的一个方面就是对“大”和“小”的理解，或者说是对量级这个概念的认识。 我们人类生活的环境，决定了我们对于大数字其实是无感的。也就是说，我们的生活环境限制了我们的认知。例如：会做PPT的人会用图表来展示数字而不是用数字的列表；还有王健林“小目标”的一个亿。 生活在今天的人依然对于大数的认知是无感的。换一个角度这也说明了人对于“大”和“小”这两个概念的理解其实受限于具体生活的环境。你习惯了某一个环境的度量，其实很难理解在量级上大得多的世界。 今天人的思维当然比一万年前的酋长们开阔许多，但是相比计算机的思维还是显得落户了很多，因为计算机自诞生就是针对大数设计的。 由于一开始就是针对海量数字设计的，因此计算机思维和人的思维就是不同的。例如，对于围棋的变化数量是数不清的，因为这个数字太大了。简单地进行数学分析一下，棋盘上每一个点最终可以的黑子、白子或者空位三种情况，棋盘一共有361个交叉点，因此最多可以有3^361（约为2*10^172）种情况。对于这么大的数字，人类对于它是无感的。 因此，这么多变化对于人类来说就是无穷无尽的。于是乎，我们人类就不把下围棋当作一种计算问题，而是把这件事情当成一种文化，称为“棋道”。 相比计算机，人类对数字的认知也受限于我们作为生物进化的速度，这是人的思维和计算机思维的另外一个不同之处。 人类进步的速度相对于计算机的进步速度就显得非常慢了，摩尔定律让计算机每十八个月性能翻一番，这相当于大约每五年涨十倍，或者每十年进步一百倍！ 很多IT从业者的思维方式并没有跟上这个时代，这是他们很难在这个行业里突破天花板的根本原因。 重点总结很多人和企业缺失了一种信息时代的思维方式，我们把它称为“计算机思维”。这并不是说计算机有思维，而是因为这种思维方式是伴随着计算机出现的。 在后信息时代，或者是即将进入智能时代，所有人都需要升级自己的思维方式，让自己的思维方式跟上这个时代。只有这样，才能不断突破职业发展的天花板。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/02/18/001职业的天花板来自认识的局限性/"},{"title":"000思维方式决定商业模式","text":"思维方式决定商业模式生活在小数字世界的人，天然地缺乏处理大数字世界里的问题的思维方式，无形之中地将人们限制在天花板之下。 例如：一是超过一百双鞋子的人，都进行了分类管理，如果鞋子再多，简单的分类已经不能解决问题了，必须对鞋子建索引；二是近万册藏书，也需要对书籍建索引，这样在找一本书的时候，先要从索引中找到那本书在第几排书架，第几个架子，第几层，然后再到那一排去找书。 人生活在小数字世界里，难免保留固有的习惯，但是既然从事了计算机这个行业，就需要按照计算机这个行业的规矩来办事，不能先验地假设数值一定不多。 其次，在计算机这个世界里，几乎任何常见的问题都已经有了优化过的答案，作为从业者，首先要擅长使用专业人士给出的，验证了无数次的答案，而不是自己凭着生活经验一拍脑袋地想出一个做法。如果为了赶时间，应该采用现有的，高质量的代码，而不是自己写一个。 因此，IT从业人员遇到职业天花板的第一个原因是一开始思维方式就错了。不克服我们先天认识上的局限性，就无法领会IT这个行业的精髓，当然事业也就做不上去。这样的道理同样适应于企业，例如曾经辉煌过的雅虎公司和中国几大门户网站今天遇到的困境，就植根于此。 在互联网2.0时代之后，，每一个人都能够产生新闻，这时候，新闻多得靠栏目分类已经无法解决了，今日头条不得不靠个性化筛选新闻。新闻门户网站的每况愈下和今日头条的兴起，实际上就是两种思维方式的对决。 可以讲，对数量大小的认知决定了商业模式，也决定了企业的成败。在新时代，更重要和有益的恐怕是在思维上要提升，这样才容易成为新时代前2%的受益者。 重点总结我们生活在小数字世界，从小数字世界总结出来的方法论无法应用到更高量级的大数世界。 对于企业，提前把自己定义在大数世界里，才能建立更有竞争力的商业模式。 作为个人，必须升级思维方式，才能适应增长迅速的大数世界，成为新时代前2%的受益者。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/02/18/000思维方式决定商业模式/"},{"title":"002工程思维：直觉和极限","text":"工程思维：直觉和极限结合生活环境，来看看我们的直觉是如何误导我们的，以及工程中“极限”这个概念如何让我们突破认识的限制，比常人更快地看清楚问题的本质。 生活中，直觉和生活常识非常有用，但是有时缺乏知识的直觉会欺骗我们。 例如：分苹果的时候，刮掉里面直径的70%的部分是小于剩余部分的。根据体积的计算，只有刮掉苹果里面直径的80%，里外的重量才大致相当。事实上，如果一个球的直径增大一倍，体积可是大7倍，而不是想象中的两三倍。 又如：Google过去面试产品经理常见的一道面试题——面试的房间里能够装下多少个高尔夫球？ 胡猜对于这道题是不行的！简单分析一下，高尔夫球大约直径4厘米，如果我们把它们整整齐齐地像立方体那样码在一起，用眼睛估摸着房间的面积和高度，用小学数学就能够解决。例如一个面积15平方，高3米的小会议室，大约可以装70万个（10,000*70）。Google考察这一题的目的是：要求产品经理在没有数据之前不要轻易给出结论。遵循一套工程思维解决问题的人，对这个问题估计出来的大致数量级不大会出错。 在上面一类问题中，更正错误的直觉并不难，但是在有些事情上要我们放弃掉我们从生活中获得的直觉，则是千难万难。 例如，在高速行进的火车上分别往前面和后面各打一束光，哪束光的速度快？按照我们的直觉，或者说低俗世界的经验，一定是往前打的光更快，因为速度是叠加的。但是，爱因斯坦的相对论告诉我们，它们是一样快的，因为光速是一个常数，产生不了叠加的效果。 极限对于工程师来讲是一个非常重要的概念。任何产品的性能都有一个物理上无法突破的极限，这个极限早就通过已有的理论直接给出。 重点总结直觉很容易误导人，掌握工程中的“极限”概念可以让我们突破认识的限制，比常人更快地看清楚问题的本质。 所谓掌握工程思维的技巧，就是要比生活超越一个层级。这就如同你看蚂蚁的爬行轨迹时，不能跟在它的后面，而要从它的上方看。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/02/18/002工程思维：直觉和极限/"},{"title":"HBase笔记总结","text":"一、存储模式1.1 行式存储&amp;列式存储定义以行为存储基准的存储方式称为行式存储，一行的数据聚合存储在一块； 以列为存储基准的存储方式称为列式存储，保证每一列的数据存储在一块。 特点 行式存储：维护大量的索引，存储的成本比较高。不能够做到线性扩展，由于维护的大量索引使得其随机读的效率很高。另外，对于事务的处理有很好的支持。 列式存储：根据同一列数据的相似性原理，有利于对数据进行压缩，其压缩效率远高于行式存储，存储成本比较低。另外，对于查询多个列的数据，可以利用并行计算提高效率。 应用场景对于单列或者相对比例较少的列并且获取频率较高，特别对于大数据的环境，需要使用到数据压缩和并行计算，就可以选择列式存储； 当表和表之间存在很多关联关系并且数据量不大，可以选择使用行式存储，其最大优势就是其事务处理的能力。 1.2 HBase列族式存储列族就是指多个数据列的组合，HBase中的每个列都归属于一个列族，列族是表schema的一部分，但列并不是的。访问控制、磁盘和内存的使用统计都是在列族层面进行的。每个列族中的列是经常需要一起访问的，这样才会使得数据存取的最优性。 HBase Table的组成： Table=RowKey（行键）+Family（列族）+Column（列）+Timestamp（版本或时间戳）+Value（值） 数据存储模式(K-V)： （RowKey，Family，Column，Timestamp） -&gt; Value 列数据属性： HBase中默认一列数据可以保存三个版本，特别对于聊天数据，标记已读、未读等属性。 数据存储原型： 按照RowKey、Column、Value、Timestamp的顺序按字典序排序： 二、数据表解析2.1 建表语句解析示例建表语句： 1234create &apos;demo:user&apos;,{NAME=&gt;&apos;b&apos;,VERSIONS=&gt;&apos;3&apos;,COMPERSSION=&gt;&apos;SNAPPY&apos;,COMPRESSION_COMPACT=&gt;&apos;SNAPPY&apos;,REPLICATION_SCOPE=&gt;1},{NAME=&gt;&apos;o&apos;,REPLICATION_SCOPE=&gt;1,COMPERSSION=&gt;&apos;SNAPPY&apos;,COMPRESSION_COMPACT=&gt;&apos;SNAPPY&apos;} NAME：列族名，必填项； VERSION：数据版本，设置一列的数据版本数量； REPLICATION_SCOPE：复制机制，主从复制。通过预写日志和Hlog实现的，当请求发送给Master的时候，log日志放入hdfs的同时，会进入REPLICATION这个队列中，通由Slave通过Zookeeper去获取，并写入Slave中的表； COMPERSSION：数据压缩的配置。 Snappy：是一种压缩特性，其编解码速率更高 2.2 数据存储目录解析在hbase-site.xml文件中设置数据存储目录: 1234&lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;/home/hbase_data&lt;/value&gt;&lt;/property&gt; .tmp：当对表进行创建和删除操作的时候，会将表移动到该目录下，然后再进行操作。它是一个临时存储当前需要修改的数据结构。 WALs：存储预写日志。 archive：存储表的归档和快照，由Master上的一个任务定时进行处理。 corrupt：用于存储损坏的日志文件，一般为空。 data：存储数据的核心目录，系统表和用户表均存储在这个目录下。 hbase.id：hbase：集群中的唯一id，用于标识hbase进程。 hbase.version：表明了文件版本信息。 oldWALs：当log已经持久化以后，WALs中的日志文件会移动到该目录下。 2.3 元信息表（系统表）元信息表同样是一张hbase表，同样拥有RowKey和列族这样的概念。存储在region server上，位于zookeeper上，用户查询数据的时候，需要先到zookeeper上获取到meta表的region server的地址再到到相应region server上进行查找，如下图所示： RowKey：格式化的region key value：保存着region server的地址，其中最重要的一个列族就是info，其中最重要的数据列是server，包含region server的地址和端口号。 元信息表的值当region进行分割、disable、enable、drop或balance等操作，或region server挂掉都会导致元信息表值的变化，Master就需要重新分配region，元信息表就会及时更新。元信息表相当于hbase的第一级索引，是hbase中最重要的系统表。 三、存储设计3.1 HBase中的LSM存储思想LSM树（Log-Structured Merge-Trees）：日志结构合并树，由两个或两个以上存储数据的结构组成的，每一个数据结构对应着自己的存储介质。 由两个树状结构组成， C0：所有数据均存储在内存 C1：所有数据均存储在磁盘之上 当一条新的记录插入的时候，先从C0中插入，当达到C0的阈值以后，就将C0中的某些数据片段迁移到C1中并合并到C1树上。当C1层级达到阈值时，合并到C2层级。由于合并排序算法是批量的、并且是顺序存储的，所以写的速度十分快。这样层层合并，文件数量越来越少，文件变得越来越大。每个层级的数据都是排序的，合并的时候通过类似归并排序的算法实现快速排序。对于删除操作，仅仅将数据标记为已删除，合并的时候跳过已标记为删除的数据，达到物理删除的效果。 LSM思想在HBase中的实现（三层存储结构）： Level 0：日志/内存，为了加速随机写的速度，先写入日志和内存中，其中日志是为了保障高可用。 Level 1：日志/内存，当达到阈值，会有异步线程将部分数据刷写到硬盘上；； Level 2：合并，由于不断地刷写会产生大量小文件，这样不利于管理和查询，需要在合适的时机启动一个异步线程进行合并操作会生成一个大文件（多路归并算法）。 3.2 数据存储模块简介RegionServer = Region + Store + MemStore + StoreFile + HFile + HLog Region ：分布式存储数据和负载均衡的最小单元，对于一个 RegionServer 可以包含很多Region，并且每一个Region 包含的数据都是互斥的，存储有用户各个行的数据。 Store ：对应表中的列族。 MemStore ：是一个内存式的数据结构，用户数据进入Region 之后会先写入MemStore当满了之后 再刷写到StoreFile 中，在StoreFile 中将数据封装成HFile再刷写到HDFS上 。 HLog：对于一个RegionServer 只有一个HLog实例。 HLog和MemStore 构成了Level 0，保证了数据的高可用和性能的低延迟。 StoreFile 和HFile 构成了Level 1，实现了不可靠数据的持久化，真正地将HBase变成了高可用的数据库系统。 3.3 Region 解析每个一个Region 都会存储在一个确定的Region Server上，数据之间是互斥的关系。HBase表在行键上分割为多个Region，它是HBae中分布式存储和负载均衡的最小单元，但不是存储的最小单元。Region 按照大小切分，每个表一行只有一个Region ，一行数据不可能分布在多个Region 上。当不断插入导致列族到达阈值之后，Region 会被水平拆分为两个Region 。Region 在Region Server的运行过程中可能出现移动，这是Master的负载均衡策略或者因为出现宕机。Region 是用户和Region Server交互的实际载体，每个Region 都有三个信息来标识： Table Name（表名） Start RowKey（起始的RowKey） Create Time（创建时间） Region 的拆分过程是：先该当前Region 下线，然后对其进行拆分，接着将子Region 加入到Meta的元信息中，再加入原Region Server上，最后同步到Master上。 3.4 HFile 解析HBase实际以HFile的形式保存在HDFS上。 HFile文件是HBase存储数据的最基础形式，它的底层是Hadoop二进制文件，是用户数据的实际载体，存储着K-V这样的数据。 Scanned block section：在顺序扫描HFile的时候，这个部分的数据块将会被读取，用户数据存储于该部分。 Nonscanned block section：在顺序扫描HFile的时候，这个部分的数据块将不会被读取。主要包含一些元数据，在访问用户数据的时候，该部分不会被扫描到。 Load-on-open section：当RegionServer 启动的时候，该部分数据会被加载到内存中，主要是HFile的一些元数据信息。 Trailer：记录了HFile的基本信息，各个部分的偏移量和寻址信息。 Data Block：是HBase中最基础的存储单元，是实际存储用户的数据结构，存储的是K-V数据。 KeyType的作用：对于HBase中的删除操作，由于HFile一旦刷写成功就不可做修改，正常插入是Put，Delete表示删除整行，DeleteColumn表示删除某一列，DeleteFamily表示删除某个列族。这就是给数据打上一个标记，称为“墓碑标记”，实际上标识数据被删除掉了。当再次扫描的时候，发现有“墓碑标记”的时候，就会在以后的某个时间点将对应的数据删除，并不是在插入的过程中就将其进行删除，这也是为了删除性能的高效性。 3.5 WAL 解析HBase的日志系统，WAL即预写日志： 其最重要的功能就是灾难恢复，解决了高可用，解决了远程备份。 WAL是通过HLog实例进行实现的，HLog是使用append方法，对日志进行追加写的功能。WAL通过序列化的number去追踪数据的改变，其内部实现使用了AtimoicLong来保证线程安全。 HLogKey： HLogSyncer：日志同步刷写类，有定时刷写和内存溢值两种工作方式。 HLogRoller：Log的大小可以通过配置文件进行设置，默认是一个小时，每经过一个小时生成一个新的Log文件。当一定时间后，就有大量的日志文件。HLogRoller是在特定的时间滚动日志生成新的日志文件，避免了单个日志文件过大。根据序列化的number（Sequence Number）对比时间，删除旧的不需要的日志文件。 3.6 Compaction 解析Compaction 会从Region Store中选择一些HFile文件进行合并，合并就是指将一些待合并的文件中的K-V对进行排序重新生成一个新的文件取代原来的待合并的文件。由于系统不断地进行刷写会产生大量小文件，这样不利于数据查找。那么将这些小文件合并成一些大文件，这样使得查找过程的I/O次数减少，提高了查找效率。其中可以分为以下两类： MinorCompaction：选取一些小的相邻的Store File进行合并一个更大的Store File，生成多个较大的Store File。 MajorCompaction：将所有的Store File合并成一个Store File，这个过程中将清理被删除的数据、TTL过期的数据、版本号超过设定版本号的数据。操作过程的时间比较长，消耗的资源也比较多。 HBase中Compaction的触发时机的因素很多，最主要的有三种： MemStore Flush ：每次执行完Flush 操作以后，都会进行判断当超过阈值就会触发一个合并。 后台线程周期性的检查：Compaction Checker会定期触发检查是否需要合并，这个线程会优先检查文件数是否大于阈值，一旦大于就会触发合并，若不满足会继续检查是否满足MajorCompaction。简单来说，就是如果当前Store中最早更新时间早于某个值，这个值成为mc time，就会触发大的合并，HBase通过这种方式来删除过期的数据，其浮动区间为[7-7 0.2, 7+7 0.2]。默认在七天会进行一次大合并（MajorCompaction）。 手动触发：通常是为了执行MajorCompaction，因为很多业务担心自动的MajorCompaction会影响性能，会选择在低峰期手动触发；还可能用户在进行完alter操作以后，希望立即生效；管理员在发现硬盘容量不够的时候会手动触发，这样可以删除大量的过期数据。 四、数据存取解析4.1 数据存取流程解析数据存储(客户端)： 提交之前会先请求Zookeeper来确定Meta表（元数据表）所在的Region Server的地址，再根据RowKey确定归属的Region Server，之后用户提交Put/Delete这样的请求，HBase客户端会将Put请求添加到本地的buffer中，符合一定的条件就会通过异步批量提交。 HBase默认设置auto flush（自动刷写）为true，表示put请求会直接提交给服务器进行处理，用户可以设置auto flush为false，这样put请求会首先放入本地的buffer中，等到buffer的大小达到一定阈值（默认是2M）后再提交。 数据存储（服务器）： 当数据到达Region Server的某个Region后，首先获取RowLock（行锁），之后再写入日志和缓存，持有行锁的时候并不会同步日志，操作完释放RowLock（行锁），随后再将同步（sync）到HDFS上，如果同步失败进行回滚操作将缓存中已写入的数据删除掉，代表插入失败。当缓存达到一定阈值（默认是64M）后，启动异步线程将数据刷写到硬盘上形成多个StoreFile，当StoreFile数量达到一定阈值后会触发合并操作。当单个StoreFile的大小达到一定大小的时候会触发一个split操作，将当前的Region切分为两个Region，再同步到Master上，原有Region会下线，子Region会被Master分配到相应的Region Server上。 数据获取（客户端）： 这里同数据存储的过程是类似的。 数据获取（服务器）： Region Server在接收到客户端的Get/Scan请求之后，首先HBase在确定的Region Server上构造一个RegionScanner准备为当前定位的Scan做检索，RegionScanner会根据列族构建StoreScanner，有多少个列族就会构建多少个StoreScanner。每个StoreScanner会为当前Store中的每个HFile构建一个StoreFileScanner，用于实际执行对应的文件检索。同时会对对应的Mem构建对应的MemStoreScanner，用于检索MemStore中的数据。构建两类Scanner的原因在于，数据可能还没有完全刷写到硬盘上，部分数据还存储于内存之中。检索完之后，就能够找到对应的K-V，再经过简单地封装就形成了ResultSet，就可以直接返回给客户端。 4.2 数据存取优化存储优化： HBase通过MemStore和WAL两种机制，实现数据顺序快速的插入，极大降低了数据存储的延迟。 检索（获取）优化： HBase使用布隆过滤器来提高随机读的性能，布隆过滤器是列族级别的配置。HBase中的每个HFile都有对应的位数组，K-V在写入HFile时，会经过几个哈希函数的映射并写入对应的位数组里面。HFile中的位数组，就是布隆过滤器中存储的值。HFile越大位数组也会越大，太大就不适合放入内存中了，因此HFile将位数组以RowKey进行了拆分，一部分连续的RowKey使用一个位数组。因此HFile会有多个位数组，在查询的时候，首先会定位到某个位数组再将该位数组加载到内存中进行过滤就行，这样减少了内存的开支。 HBase中存在两种布隆过滤器： Row：根据RowKey来过滤StoreFile，这种情况可以针对列族和列都相同，只有RowKey不同的情况； RowCol：根据RowKey+ColumnQualifier（列描述符）来过滤StoreFile，这种情况是针对列族相同，列和RowKey不同的情况。 五、特点 容量大：HBase单表可以有百亿行、百万列，数据矩阵横向和纵向两个纬度所支持的数据量级都非常具有弹性； 面向列：列是可以动态增加的，不需要指定列，面向列的存储和权限控制，并支持独立检索； 多版本：每一个列的数据存储有个多Version； 稀疏性：为空的列不占用存储空间； 扩展性：底层依赖于HDFS，空间不够的时候只需要横向扩展即可； 高可靠性：副本机制保证了数据的可靠性； 高性能：写入性能高，底层使用LSM数据结构和RowKey有序排序等架构上的独特设计；读性能高，使用region切分、主键索引和缓存机制使得具备随机读取性能高。 六、和关系型数据库的对比区别： 列动态增加； 数据自动切分； 高并发读写； 不支持条件查询 HBase shell命令 参考资料https://www.imooc.com/learn/996 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/05/18/HBase/"},{"title":"Java中锁的总结","text":"Java中锁的总结一、锁的类型1. 自旋锁自旋锁是计算机科学用于多线程同步的一种锁，线程反复检查锁变量是否可用。由于线程在这一过程中保持执行，因此是一种忙等待。一旦获取了自旋锁，线程会一直保持该锁，直至显式释放自旋锁。 自旋锁避免了进程上下文的调度开销，因此对于线程只会阻塞很短时间的场合是有效的。因此操作系统的实现在很多地方往往用自旋锁。 线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很短的时间内阻塞并唤醒线程显然不值得，为此引入了自旋锁。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。 自旋锁有以下特点： 用于临界区互斥 在任何时刻最多只能有一个执行单元获得锁 要求持有锁的线程所占用的时间尽可能短 等待锁的线程进入忙循环状态 2. 偏向锁偏向锁是在JDK 1.6之后加入的，其目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。其思想是偏向于让第一个获得锁的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。 当锁对象第一次被线程获得的时候，进入偏向状态，标记为 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word 中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。 当有另外一个线程去尝试获取这个锁对象时，偏向模式就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态。偏向锁、轻量级锁的状态转化如下所示： 3. 轻量级锁 轻量级锁是JDK 1.6之后加入的新型锁机制，是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。 Mark Word（HotSpot虚拟机的对象头的第一部分）是实现轻量级锁和偏向锁的关键。对象头信息是与对象自身定义的数据无关的额外存储成本，它会根据对象的状态复用自己的存储空间。32位的Mark Word结构如下图示： 当尝试获取一个锁对象时，如果锁对象标记为 0 01，说明锁对象的锁为无锁（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。 如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。 轻量级锁能够提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”，如果没有竞争，使用CAS操作能够避免使用互斥操作的开销。但如果存在锁竞争，除了互斥量的开销以外，还有额外的CAS操作，因此在竞争的情况下，轻量级锁会比传统的重量级锁更慢。 二、锁的策略1. 乐观锁 总是假设最好的情况，每次去读数据的时候都认为别人不会修改，所以不会上锁， 但是在更新的时候会判断一下在此期间有没有其他线程更新该数据， 可以使用版本号机制和CAS算法实现。 乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。 在Java中java.util.concurrent.atomic包下面的原子变量类就是基于CAS实现的乐观锁。 2. 悲观锁 总是假设最坏的情况，每次去读数据的时候都认为别人会修改，所以每次在读数据的时候都会上锁， 这样别人想读取数据就会阻塞直到它获取锁 （共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。 传统的关系型数据库里边就用到了很多悲观锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中的悲观锁就是Synchronized,AQS框架下的锁则是先尝试CAS乐观锁去获取锁，获取不到，才会转换为悲观锁，如ReentrantLock 乐观锁好比生活中乐观的人总是想着事情往好的方向发展，悲观锁好比生活中悲观的人总是想着事情往坏的方向发展。 这两种人各有优缺点，不能不以场景而定说一种人好于另外一种人。 三、加锁过程的描述 当代码进入同步块的时候，假设此对象没有被锁定（即无锁状态，锁的标志位为01）。虚拟机首先会将在当前线程的栈帧里面新建一个“锁记录”（Lock Record）的空间，用于存储锁对象当前Mark Word的一份拷贝（Displaced Mark Word）； 将对象头的Mark Word拷贝到“锁记录”上； 虚拟机将使用CAS操作尝试将锁对象的Mark Word更新指向“锁记录”（Lock Record）。 如果更新成功，此时该线程就拥有了该对象的锁，并且对象头Mark Word的锁标志位改为00（轻量级锁）； 如果上一步中的CAS操作更新失败，虚拟机首先检查对象头的Mark Word是否指向当前线程的栈帧，如果是，则说明当前线程已经拥有了当前对象的锁，那就可以直接进入同步快继续执行； 否则，说明当前锁已被其他线程占用，这时出现了两个以上的线程争用同一把锁，那轻量级锁就失效，膨胀成为重量级锁（锁标志为10）。Mark Word中存储的就是指向重量级锁的指针，后面等待锁的其他线程也要进入阻塞状态，而当前线程则使用自旋来获取锁。 四、解锁过程的描述 通过CAS尝试把线程中复制的Displaced Mark Word对象替换当前对象的Mark Word； 如果替换成功，整个同步过程就完成了； 如果替换失败，说明有其他线程尝试过获取该锁（锁已膨胀），那就要在释放锁的同时，唤醒被挂起的线程。 五、锁的内存语义当线程释放锁的时候，Java内存模型会把该线程对应的本地内存中的共享变量刷新到主内存中； 而当线程获取锁的时候，Java内存模型会把该线程对应的本地内存置为无效，从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。 线程之间相当于通过主内存进行通信，如下图所示： 六、锁的汇总 参考资料 《深入理解Java虚拟机》 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/03/05/Java中锁的总结/"},{"title":"003为什么计算机不是万能的","text":"为什么计算机不是万能的从计算的本质来看看计算机的极限，这些思考方式来自于图灵博士。 在20世纪30年代中期，图灵思考的三个问题： 世界上是否所有数学问题都有明确的答案？ 如果有明确的答案，是否可以通过有限步骤的计算得到答案？ 对于那些有可能在有限步骤计算出来的数学问题，能否有一种假想的机械，让它不断运动，最后当机器停下来的时候，那个数学问题就解决了？ 像图灵这样超越时代的人，他不是在跟在蚂蚁后面来观察一件事情发展的规律，而是在前面等着大家，找到极限所在，然后他告诉大家，就在极限里寻找具体问题的答案吧，不要浪费时间纠结没有意义的事情，也就是那些试图超越极限的事情。 今天所有的计算机，包括全世界正在设计的新的计算机，从解决问题的能力来讲，都没有超出图灵机的范畴。图灵，其实为今天的计算机和很长时间以后的未来计算机所能解决的问题划了一道不可超越的边界。 人工智能的边界 世界上很多问题，其中只有一小部分是数学问题； 在数学问题中，只有一小部分是有解的； 在有解的问题中，只有一部分是理想状态的图灵机可以解决的； 在后一类的问题中，又只有一部分是今天实际的计算机可以解决的； 而人工智能可以解决的问题，又只是计算机可以解决问题的一部分。 图灵受到了另一位数学大师希尔伯特的启发。希尔伯特在1900年的巴黎国际数学家大会上，提出了23个重要的、根本性的数学问题（也被称为希尔伯特问题）。 其中第十个问题讲的是这样一件事，“随便给一个不确定的方程，能否通过有限步骤的运算，判定它是否存在整数解？”这个答案是否定的，那么就说明很多数学问题其实上帝也不知道答案是否存在。正是希尔伯特的这个提问，让图灵明白了计算机的极限所在。 第二个给予图灵巨大启示的人是他的精神导师冯·诺依曼。图灵在读了他的《量子力学的数学原理》一书后，意识到计算来自于确定性的机械的运动。 至于21世纪的电子计算机，里面电子的运动其实等价于机械运动。图灵同时猜测人的意识来自于测不准原理，这是宇宙本身的规律。图灵从此得出结论，计算的确定的，而意识可以是不定的，两者不可能划等号。 很多人胡思乱想计算机是否有意识，其实早在80年前，图灵就感到两者是两回事，这就是任何计算机的边界。 从图灵的事迹上，我们可以得到是启示是：要和比自己强的人在一起，这一点很重要，因为只有这样我们的认知才能提升。反之，如果总是和臭棋篓子下棋，只能越下越臭。 重点总结 图灵和常人思维的方式的差别在于：图灵是先找到极限所在，然后再极限里寻找具体问题的答案，而不是浪费时间去做那些试图超越极限的事情。 图灵机是一个数学模型，今天所有的计算机，包括正在设计的新的计算机，从从解决问题的能力来讲，都没有超出图灵机的范畴。 人工智能所能解决的问题只是世界上问题的很小一部分。现在世界上没有解决的问题太多，要想办法解决各种问题，而不是杞人忧天，担心人工智能太强大。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/02/18/003为什么计算机不是万能的/"},{"title":"Java中常见的几个OOM的情况","text":"除了PC（程序计数器）以外，Java虚拟机内存区域的都有可能发生OOM（OutOfMemoryError）。 Java堆溢出Java堆是用于存储对象实例的，只要不断地创建对象，并且保证GC Roots到对象之间有可达路径避免垃圾回收机制被清楚，那么在对象数量到达最大堆的容量限制之后便会产生OOM异常。 解决思路一般的手段是：先通过内存映像工具对Dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏还是内存溢出。 如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链。这样就能够找到泄漏的对象是通过怎么样的路径与GC Roots相关联的导致垃圾回收机制无法将其回收。掌握了泄漏对象的类信息和GC Roots引用链的信息，就可以比较准确地定位泄漏代码的位置。 如果不存在泄漏，换句话说，就是内存中的对象确实必须存活着，那么此时就需要通过虚拟机的堆参数（ -Xmx和-Xms）来适当调大参数；从代码上检查是否存在某些对象存活时间过长、持有时间过长的情况，尝试减少运行时内存的消耗。 -Xmx : 最大堆空间； -Xms : 初始堆空间大小，如果初始堆空间耗尽，JVM会对堆空间扩容，其扩展上限为最大堆空间。通常-Xms与-Xmx设置为同样大小，避免扩容造成性能损耗。 虚拟机栈和本地方法栈溢出由于在HotSpot虚拟机上并不区分虚拟机栈和本地方法栈，因此栈容量只能由-Xss参数设定。在Java虚拟机规范中描述了两种异常： StackOverflowError ：如果线程请求的栈深度超过了虚拟机所允许的最大深度，就会抛出该异常； OutOfMemoryError：如果虚拟机在拓展栈的时候，无法申请到足够的空间，就会抛出该异常。 对于这两种异常来说，存在着一些互相重叠的地方：当栈空间无法继续分配的时候，到底是内存太小还是已使用的栈空间太大，其实只是对同一件事情的两种描述罢了。 当在单线程环境下，无论是由于栈帧太大还是虚拟机栈容量太小，当内存无法继续分配的时候，虚拟机抛出的都是StackOverflowError 异常。 在多线程环境下，如果为每个线程的栈分配的内存越大，反而越容易产生OOM异常。每个线程分配到的栈容量越大，可以建立的线程数量就自然减少了，那么在新建立线程的时候就很容易把内存耗尽，产生OOM异常。虚拟机默认参数栈深度大多数情况下能够达到1000~2000，对于正常的方法调用（包括递归）是完全够用的。但是，在多线程环境下的OOM，就只能通过减少最大堆和减少栈容量来换取更多的线程数量。 方法区和运行时常量池溢出方法区用于存放Class的相关信息，如类名、访问修饰符、常量池、字段描述、方法描述等。当前的一些主流框架，如Spring、Hibernate，对于类进行增强的时候都会使用到CGLib这类字节码技术，增强的类越多，就需要越大的方法区来保证动态生成Class可以加载入内存，这样的情况下可能会造成方法区的OOM异常。 在经常动态生成大量Class的应用中，需要特别注意类的回收状况。这类场景还在：大量JSP或动态生成JSP文件的应用（JSP第一次运行时需要编译为Java类）、基于OSGi的应用（即使是同一个类文件，被不同的加载器加载也会视作不同的类）等。 直接内存溢出直接内存（DirectMemory）容量可以通过-XX : MaxDirectMemorySize指定，如果不指定，则默认与Java最大堆（-Xmx指定）一样。 由于直接内存（DirectMemory）导致的内存溢出，一个明显的特征是在Heap Dump文件中不会看见明显的异常，如果发现OOM之后Dump文件很小，而程序中又直接或间接使用了NIO，就可以考虑检查一下是否为直接内存（DirectMemory）溢出异常。 参考资料 《深入理解Java虚拟机（第2版）》 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/03/14/Java中常见的几个OOM的情况/"},{"title":"有关I/O多路复用的总结","text":"什么是IO多路复用呢？ IO多路复用的实现有哪些呢？ 它们的区别是什么呢？ 为了回答上面三个问题，我总结得到了这篇文章。 什么是IO多路复用呢？IO多路复用是一种可以监视多个描述符，一旦某个描述符就绪（读、写就绪），能够通知进程进行相应的读写操作的机制。 描述符：内核（kernel）利用文件描述符（file descriptor）来访问文件。 文件描述符是非负整数。 打开现存文件或新建文件时，内核会返回一个文件描述符。 读写文件也需要使用文件描述符来指定待读写的文件。 IO多路复用是同步非阻塞方式，由于同步非阻塞方式需要不断主动轮询，轮询占据了很大一部分过程，轮询会消耗大量的CPU时间，而 “后台” 可能有多个任务在同时进行，人们就想到了循环查询多个任务的完成状态，只要有任何一个任务完成，就去处理它。如果轮询不是进程的用户态，而是有人帮忙就好了。那么这就是所谓的 “IO 多路复用”。UNIX/Linux 下的 select、poll、epoll 就是干这个的（epoll 比 poll、select 效率高，做的事情是一样的）。 其最大优势就系统开销小，系统不必要创建过多的进程/线程，减少了上下文切换的消耗和系统资源。 主要适用如下场合： 如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用； 如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用； 如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用； 当客户端需要处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用。 IO多路复用的实现有哪些呢？在内核中的实现有 select、poll、epoll ，其出现顺序也是如此。 select用户线程会启动一个监视Socket调用select函数以后会阻塞，直到有描述符就绪，或超时，函数才返回。当函数返回以后，再遍历fdset来寻找就绪的描述符。select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。 有以下缺点： 每次调用都需要把fd集合从用户态拷贝到内核态，这样会使得用户空间和内核空间在传递该结构时复制开销大； 每次扫描时采取线性扫描内核中的所有fd，效率很低； 单个线程处理的IO数量由fd限制，默认值为1024。 然而，它有良好的跨平台性，几乎所有平台都可以支持。 pollpoll和select的实现是类似的，区别在于它是基于链表存储的，没有最大连接的限制。 epollepoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait： epoll_create是创建一个epoll句柄； epoll_ctl是向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理； epoll_wait则是等待事件的产生。 epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。 对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。 对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。 对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。 如果没有大量的空闲连接或者“死”连接，epoll的效率并不会比select/poll高很多，但是当有大量空闲连接的时候，就会发现epoll的效率会大大提高。 它们的区别是什么呢？三者的区别体现在三个方面： 1. 支持的最大连接数 select：最大连接数由FD_SIZE决定，默认值为1024； poll：基于链表存储，没有最大连接数的限制； epoll：最大连接数由内存决定，1G的内存可以打开约10万个连接。 2. FD剧增后带来的IO效率问题 select：每次调用都会对连接进行线性遍历，随着FD的增加使得遍历效率降低； poll：同上； epoll：fd上是利用回调函数，只有活跃的socket才会主动调用callback，在活跃socket较少的情况下，不存在前者的线性下降的性能问题，当所有socket都很活跃的时候，可能会出现性能问题。 3. 消息传递方式 select：通过拷贝的方式将内核的消息传递给用户空间； poll：同上； epoll：通过共享内存的方式，实现内核态和用户态的通信。 参考资料 https://www.jianshu.com/p/dfd940e7fca2 https://blog.csdn.net/qq_34309305/article/details/79235395 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/05/24/IO多路复用总结/"},{"title":"利用Hexo搭建自己的博客","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2018/10/22/利用Hexo搭建自己的博客/"},{"title":"Spring的阅读笔记","text":"Spring的阅读笔记 前言 在阅读 Spring的源代码（依赖注入部分和面向切面编程部分）时遇到不少困惑，庞大的类文件结构、纷繁复杂的方法调用、波诡云谲的多态实现，让自己深陷其中、一头雾水。后来注意到 code4craft 的 tiny-spring 项目，实现了一个微型的 Spring，提供对 IoC 和 AOP的最基本支持，麻雀虽小，五脏俱全，对 Spring 的认知清晰了不少。这个微型框架的结构包括文件名、方法名都是参照 Spring来实现的，对于初读 Spring 的学习者，作为研究 Spring 的辅助工具应该能够受益匪浅。 在研究 tiny-spring的时候，收获颇多，把对这个微型框架的一些分析写了下来，行文可能有点紊乱。 本文结构 第一部分 IoC 容器的实现 对应了 tiny-spring 的 step-1 到 step-5 部分，这 5 个 step 实现了基本的 IoC 容器，支持singleton类型的bean，包括初始化、属性注入、以及依赖 Bean 注入，可从 XML 中读取配置，XML 读取方式没有具体深入。 第二部分 AOP 容器的实现 对应了 tiny-spring 的 step-6 到 step-9 部分。step-10 中对 cglib 的支持没有分析。这 4 个 step 可以使用 AspectJ 的语法进行 AOP编写，支持接口代理。考虑到 AspectJ 语法仅用于实现 execution(“***”) 部分的解析，不是主要内容，也可以使用 Java的正则表达式粗略地完成，因此没有关注这些细节。参考书目 《Spring 实战》《Spring 技术内幕》 tiny-spring 分析IoC 容器的实现文件结构ResourceBeanDefinitionBeanFactoryApplicationContext设计模式模板方法模式代理模式AOP 的实现重新分析 IoC 容器BeanFactory 的构造与执行ApplicationContext 的构造和执行IoC 实现的一些思考与分析分析 1：AOP 可以在何处被嵌入到 IoC 容器中去？分析 2：BeanFactory 和 ApplicationContext 设计上的耦合分析 3：tiny-spring 总体流程的分析JDK 对动态代理的支持AOP 的植入与实现细节在 Bean 初始化过程中完成 AOP 的植入AOP 中动态代理的实现步骤动态代理的内容动态代理的步骤设计模式代理模式策略模式为 tiny-spring 添加拦截器链为什么 GitHub 不支持 TOC IoC 容器的实现文件结构Resource以 Resource 接口为核心发散出的几个类，都是用于解决 IoC 容器中的内容从哪里来的问题，也就是 配置文件从哪里读取、配置文件如何读取 的问题。 类名 说明Resource 接口，标识一个外部资源。通过 getInputStream() 方法 获取资源的输入流 。UrlResource 实现 Resource 接口的资源类，通过 URL 获取资源。ResourceLoader 资源加载类。通过 getResource(String) 方法获取一个 Resouce 对象，是 获取 Resouce 的主要途径 。注： 这里在设计上有一定的问题，ResourceLoader 直接返回了一个 UrlResource，更好的方法是声明一个 ResourceLoader 接口，再实现一个 UrlResourceLoader 类用于加载 UrlResource。 BeanDefinition以 BeanDefinition 类为核心发散出的几个类，都是用于解决 Bean 的具体定义问题，包括 Bean 的名字是什么、它的类型是什么，它的属性赋予了哪些值或者引用，也就是 如何在 IoC 容器中定义一个 Bean，使得 IoC 容器可以根据这个定义来生成实例 的问题。 类名 说明BeanDefinition 该类保存了 Bean 定义。包括 Bean 的 名字 String beanClassName、类型 Class beanClass、属性 PropertyValues propertyValues。根据其 类型 可以生成一个类实例，然后可以把 属性 注入进去。propertyValues 里面包含了一个个 PropertyValue 条目，每个条目都是键值对 String - Object，分别对应要生成实例的属性的名字与类型。在 Spring 的 XML 中的 property 中，键是 key ，值是 value 或者 ref。对于 value 只要直接注入属性就行了，但是 ref 要先进行解析。Object 如果是 BeanReference 类型，则说明其是一个引用，其中保存了引用的名字，需要用先进行解析，转化为对应的实际 Object。BeanDefinitionReader 解析 BeanDefinition 的接口。通过 loadBeanDefinitions(String) 来从一个地址加载类定义。AbstractBeanDefinitionReader 实现 BeanDefinitionReader 接口的抽象类（未具体实现 loadBeanDefinitions，而是规范了 BeanDefinitionReader 的基本结构）。内置一个 HashMap rigistry，用于保存 String - beanDefinition 的键值对。内置一个 ResourceLoader resourceLoader，用于保存类加载器。用意在于，使用时，只需要向其 loadBeanDefinitions() 传入一个资源地址，就可以自动调用其类加载器，并把解析到的 BeanDefinition 保存到 registry 中去。XmlBeanDefinitionReader 具体实现了 loadBeanDefinitions() 方法，从 XML 文件中读取类定义。BeanFactory以 BeanFactory 接口为核心发散出的几个类，都是用于解决 IoC 容器在 已经获取 Bean 的定义的情况下，如何装配、获取 Bean 实例 的问题。 类名 说明BeanFactory 接口，标识一个 IoC 容器。通过 getBean(String) 方法来 获取一个对象AbstractBeanFactory BeanFactory 的一种抽象类实现，规范了 IoC 容器的基本结构，但是把生成 Bean 的具体实现方式留给子类实现。IoC 容器的结构：AbstractBeanFactory 维护一个 beanDefinitionMap 哈希表用于保存类的定义信息（BeanDefinition）。获取 Bean 时，如果 Bean 已经存在于容器中，则返回之，否则则调用 doCreateBean 方法装配一个 Bean。（所谓存在于容器中，是指容器可以通过 beanDefinitionMap 获取 BeanDefinition 进而通过其 getBean() 方法获取 Bean。）AutowireCapableBeanFactory 可以实现自动装配的 BeanFactory。在这个工厂中，实现了 doCreateBean 方法，该方法分三步：1，通过 BeanDefinition 中保存的类信息实例化一个对象；2，把对象保存在 BeanDefinition 中，以备下次获取；3，为其装配属性。装配属性时，通过 BeanDefinition 中维护的 PropertyValues 集合类，把 String - Value 键值对注入到 Bean 的属性中去。如果 Value 的类型是 BeanReference 则说明其是一个引用（对应于 XML 中的 ref），通过 getBean 对其进行获取，然后注入到属性中。ApplicationContext以 ApplicationContext 接口为核心发散出的几个类，主要是对前面 Resouce 、 BeanFactory、BeanDefinition 进行了功能的封装，解决 根据地址获取 IoC 容器并使用 的问题。 类名 说明ApplicationContext 标记接口，继承了 BeanFactory。通常，要实现一个 IoC 容器时，需要先通过 ResourceLoader 获取一个 Resource，其中包括了容器的配置、Bean 的定义信息。接着，使用 BeanDefinitionReader 读取该 Resource 中的 BeanDefinition 信息。最后，把 BeanDefinition 保存在 BeanFactory 中，容器配置完毕可以使用。注意到 BeanFactory 只实现了 Bean 的 装配、获取，并未说明 Bean 的 来源 也就是 BeanDefinition 是如何 加载 的。该接口把 BeanFactory 和 BeanDefinitionReader 结合在了一起。AbstractApplicationContext ApplicationContext 的抽象实现，内部包含一个 BeanFactory 类。主要方法有 getBean() 和 refresh() 方法。getBean() 直接调用了内置 BeanFactory 的 getBean() 方法，refresh() 则用于实现 BeanFactory 的刷新，也就是告诉 BeanFactory 该使用哪个资源（Resource）加载类定义（BeanDefinition）信息，该方法留给子类实现，用以实现 从不同来源的不同类型的资源加载类定义 的效果。ClassPathXmlApplicationContext 从类路径加载资源的具体实现类。内部通过 XmlBeanDefinitionReader 解析 UrlResourceLoader 读取到的 Resource，获取 BeanDefinition 信息，然后将其保存到内置的 BeanFactory 中。注 1：在 Spring 的实现中，对 ApplicatinoContext 的分层更为细致。AbstractApplicationContext 中为了实现 不同来源 的 不同类型 的资源加载类定义，把这两步分层实现。以“从类路径读取 XML 定义”为例，首先使用 AbstractXmlApplicationContext 来实现 不同类型 的资源解析，接着，通过 ClassPathXmlApplicationContext 来实现 不同来源 的资源解析。注 2：在 tiny-spring 的实现中，先用 BeanDefinitionReader 读取 BeanDefiniton 后，保存在内置的 registry （键值对为 String - BeanDefinition 的哈希表，通过 getRigistry() 获取）中，然后由 ApplicationContext 把 BeanDefinitionReader 中 registry 的键值对一个个赋值给 BeanFactory 中保存的 beanDefinitionMap。而在 Spring 的实现中，BeanDefinitionReader 直接操作 BeanDefinition ，它的 getRegistry() 获取的不是内置的 registry，而是 BeanFactory 的实例。如何实现呢？以 DefaultListableBeanFactory 为例，它实现了一个 BeanDefinitonRigistry 接口，该接口把 BeanDefinition 的 注册 、获取 等方法都暴露了出来，这样，BeanDefinitionReader 可以直接通过这些方法把 BeanDefiniton 直接加载到 BeanFactory 中去。 设计模式注：此处的设计模式分析不限于 tiny-spring，也包括 Spring 本身的内容 模板方法模式该模式大量使用，例如在 BeanFactory 中，把 getBean() 交给子类实现，不同的子类 **BeanFactory 对其可以采取不同的实现。 代理模式在 tiny-spring 中（Spring 中也有类似但不完全相同的实现方式），ApplicationContext 继承了 BeanFactory 接口，具备了 getBean() 功能，但是又内置了一个 BeanFactory 实例，getBean() 直接调用 BeanFactory 的 getBean() 。但是ApplicationContext 加强了 BeanFactory，它把类定义的加载也包含进去了。 AOP 的实现重新分析 IoC 容器注：以下所说的 BeanFactory 和 ApplicationContext 不是指的那几个最基本的接口类（例如 BeanFactory 接口，它除了 getBean 空方法之外，什么都没有，无法用来分析。），而是指这一类对象总体的表现，比如 ClasspathXmlApplicationContext、FileSystemXmlApplicationContext 都算是 ApplicationContext。 BeanFactory 的构造与执行BeanFactory 的核心方法是 getBean(String) 方法，用于从工厂中取出所需要的 Bean 。AbstractBeanFactory 规定了基本的构造和执行流程。 getBean 的流程：包括实例化和初始化，也就是生成 Bean，再执行一些初始化操作。 doCreateBean ：实例化 Bean。a. createInstance ：生成一个新的实例。b. applyProperties ：注入属性，包括依赖注入的过程。在依赖注入的过程中，如果 Bean 实现了 BeanFactoryAware 接口，则将容器的引用传入到 Bean 中去，这样，Bean 将获取对容器操作的权限，也就允许了 编写扩展 IoC 容器的功能的 Bean。initializeBean(bean) ： 初始化 Bean。a. 从 BeanPostProcessor 列表中，依次取出 BeanPostProcessor 执行 bean = postProcessBeforeInitialization(bean,beanName) 。（为什么调用 BeanPostProceesor 中提供方法时，不是直接 post…(bean,beanName) 而是 bean = post…(bean,beanName) 呢？见分析1 。另外，BeanPostProcessor 列表的获取有问题，见分析2。）b. 初始化方法（tiny-spring 未实现对初始化方法的支持）。c. 从 BeanPostProcessor 列表中， 依次取出 BeanPostProcessor 执行其 bean = postProcessAfterInitialization(bean,beanName)。ApplicationContext 的构造和执行ApplicationContext 的核心方法是 refresh() 方法，用于从资源文件加载类定义、扩展容器的功能。 refresh 的流程： loadBeanDefinitions(BeanFactory) ：加载类定义，并注入到内置的 BeanFactory 中，这里的可扩展性在于，未对加载方法进行要求，也就是可以从不同来源的不同类型的资源进行加载。registerBeanPostProcessors(BeanFactory) ：获取所有的 BeanPostProcessor，并注册到 BeanFactory 维护的 BeanPostProcessor 列表去。onRefresh ：a. preInstantiateSingletons ：以单例的方式，初始化所有 Bean。tiny-spring 只支持 singleton 模式。IoC 实现的一些思考与分析分析 1：AOP 可以在何处被嵌入到 IoC 容器中去？在 Bean 的初始化过程中，会调用 BeanPostProcessor 对其进行一些处理。在它的 postProcess…Initialization 方法中返回了一个 Bean，这个返回的 Bean 可能已经不是原来传入的 Bean 了，这为实现 AOP 的代理提供了可能！以 JDK 提供的动态代理为例，假设方法要求传入的对象实现了 IObj 接口，实际传入的对象是 Obj，那么在方法中，通过动态代理，可以 生成一个实现了 IObj 接口并把 Obj 作为内置对象的代理类 Proxy 返回，此时 Bean 已经被偷偷换成了它的代理类。 分析 2：BeanFactory 和 ApplicationContext 设计上的耦合BeanFactory 中的 BeanPostProcessor 的列表是哪里生成的呢？是在 ApplicationContext 中的 refresh 方法的第二步，这里设计上应该有些问题，按理说 ApplicationContext 是基于 BeanFactory 的，BeanFactory 的属性的获取，怎么能依赖于 ApplicationContext 的调用呢？ 分析 3：tiny-spring 总体流程的分析总体来说，tiny-spring 的 ApplicaitonContext 使用流程是这样的： ApplicationContext 完成了类定义的读取和加载，并注册到 BeanFactory 中去。 ApplicationContext 从 BeanFactory 中寻找 BeanPostProcessor，注册到 BeanFactory维护的 BeanPostProcessor 列表中去。 ApplicationContext 以单例的模式，通过主动调用 getBean 实例化、注入属性、然后初始化 BeanFactory 中所有的 Bean。由于所有的 BeanPostProcessor 都已经在第 2 步中完成实例化了，因此接下来实例化的是普通 Bean，因此普通 Bean 的初始化过程可以正常执行。 调用 getBean 时，委托给 BeanFactory，此时只是简单的返回每个 Bean 单例，因为所有的 Bean 实例在第三步都已经生成了。 JDK 对动态代理的支持JDK 中几个关键的类： 类名 说明Proxy 来自 JDK API。提供生成对象的动态代理的功能，通过 Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) 方法返回一个代理对象。InvocationHandler 来自 JDK API。通过 Object invoke(Object proxy, Method method,Object[] args) 方法实现代理对象中方法的调用和其他处理。假设以下的情况： 对象 obj 实现了 IObj 接口，接口中有一个方法 func(Object[] args)。对象 handler 是 InvocationHandler 的实例。那么，通过 Proxy 的 newProxyInstance(obj.getClassLoader(), obj.getClass().getInterfaces(), handler，可以返回 obj 的代理对象 proxy。 当调用 proxy.func(args) 时，对象内部将委托给 handler.invoke(proxy, func, args) 函数实现。 因此，在 handler 的 invoke 中，可以完成对方法拦截的处理。可以先判断是不是要拦截的方法，如果是，进行拦截（比如先做一些操作，再调用原来的方法，对应了 Spring 中的前置通知）；如果不是，则直接调用原来的方法。 AOP 的植入与实现细节在 Bean 初始化过程中完成 AOP 的植入解决 AOP 的植入问题，首先要解决 在 IoC 容器的何处植入 AOP 的问题，其次要解决 为哪些对象提供 AOP 的植入 的问题。tiny-spring 中 AspectJAwareAdvisorAutoProxyCreator 类（以下简称 AutoProxyCreator）是实现 AOP 植入的关键类，它实现了两个接口： BeanPostProcessor ：在 postProcessorAfterInitialization 方法中，使用动态代理的方式，返回一个对象的代理对象。解决了 在 IoC 容器的何处植入 AOP 的问题。BeanFactoryAware ：这个接口提供了对 BeanFactory 的感知，这样，尽管它是容器中的一个 Bean，却可以获取容器的引用，进而获取容器中所有的切点对象，决定对哪些对象的哪些方法进行代理。解决了 为哪些对象提供 AOP 的植入 的问题。AOP 中动态代理的实现步骤动态代理的内容首先，要知道动态代理的内容（拦截哪个对象、在哪个方法拦截、拦截具体内容），下面是几个关键的类： 类名 说明PointcutAdvisor 切点通知器，用于提供 对哪个对象的哪个方法进行什么样的拦截 的具体内容。通过它可以获取一个切点对象 Pointcut 和一个通知器对象 Advisor。Pointcut 切点对象可以获取一个 ClassFilter 对象和一个 MethodMatcher 对象。前者用于判断是否对某个对象进行拦截（用于 筛选要代理的目标对象），后者用于判断是否对某个方法进行拦截（用于 在代理对象中对不同的方法进行不同的操作）。Advisor 通知器对象可以获取一个通知对象 Advice 。就是用于实现 具体的方法拦截，需要使用者编写，也就对应了 Spring 中的前置通知、后置通知、环切通知等。动态代理的步骤接着要知道动态代理的步骤： AutoProxyCreator（实现了 BeanPostProcessor 接口）在实例化所有的 Bean 前，最先被实例化。其他普通 Bean 被实例化、初始化，在初始化的过程中，AutoProxyCreator 加载 BeanFactory 中所有的 PointcutAdvisor（这也保证了 PointcutAdvisor 的实例化顺序优于普通 Bean。），然后依次使用 PointcutAdvisor 内置的 ClassFilter，判断当前对象是不是要拦截的类。如果是，则生成一个 TargetSource（要拦截的对象和其类型），并取出 AutoProxyCreator 的 MethodMatcher（对哪些方法进行拦截）、Advice（拦截的具体操作），再，交给 AopProxy 去生成代理对象。AopProxy 生成一个 InvocationHandler，在它的 invoke 函数中，首先使用 MethodMatcher 判断是不是要拦截的方法，如果是则交给 Advice 来执行（Advice 由用户来编写，其中也要手动/自动调用原始对象的方法），如果不是，则直接交给 TargetSource 的原始对象来执行。设计模式代理模式通过动态代理实现，见分析1中的内容，不再赘述。 策略模式生成代理对象时，可以使用 JDK 的动态代理和 Cglib 的动态代理，对于不同的需求可以委托给不同的类实现。 为 tiny-spring 添加拦截器链tiny-spring 不支持拦截器链，可以模仿 Spring 中拦截器链的实现，实现对多拦截器的支持。tiny-spring 中的 proceed() 方法是调用原始对象的方法 method.invoke(object,args)。（参见 ReflectiveMethodInvocation 类)为了支持多拦截器，做出以下修改： 将 proceed() 方法修改为调用代理对象的方法 method.invoke(proxy,args)。在代理对象的 InvocationHandler 的 invoke 函数中，查看拦截器列表，如果有拦截器，则调用第一个拦截器并返回，否则调用原始对象的方法。 在此输入正文 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2018/10/24/Spring的阅读笔记/"},{"title":"论文笔记03：H-Scheduler Storage-Aware Task Scheduling for Heterogeneous-Storage Spark Clusters","text":"发表于2018 一、存在的问题Spark集群在存储介质（HDDs 和 SSDs）异构的问题，导致不同结点的读写速度不一致，没有充分地利用异构存储的优势。当前针对于异构环境下的调度，只考虑了计算资源，而忽视了存储设备异构性的问题。 二、提出的方法2.1 创新点考虑Spark集群上存储介质的不同对任务完成时间的影响，提出了对于异构存储介质集群存储感知的任务调度策略。 2.2 结果实验结果显示，H-Scheduler能够降低Job 73.6%的执行时间。 三、背景&amp;动机 支持异构存储介质的HDFS； 支持异构存储介质的HDFS和当前调度策略的匹配： 由于网速的提升，对于数据本地化的影响对于任务执行的影响在降低； 四、设计H-Scheduler在调度决策同时考虑将数据本地化和存储介质类型这两个因素。 第一步 任务分类H-Scheduler在调度之前应该知道处理每个任务的存储介质类型，根据任务的本地性和数据块存储介质的类型将任务进行分类，分为以下四种类型： SSD task remote SSD task local HDD task remote HDD task 四种类型的任务执行时间依次递增 将任务分成SSD中的任务和HDD中的任务两大类 第二步 任务优先级设置根据四种任务类型来决定任务的执行顺序任务的优先级为： local SSD task &gt; local HDD task &gt; remote HDD task &gt; remote SSD task. 第三步 节点的选择在选择执行远程任务的时候，有以下三种策略： 随机选择 最多优先选择：选择拥有本地任务最多的节点 最少优先选择：选择拥有本地任务最少的节点 五、算法算法1 适合的两个场景： 工作量是计算密集型的，任务数量很大； 能耗低要求较高，对于SLA截止时间要求较低。 六、实验四种典型的工作负载： Wordcount(500GB)：CPU密集型任务 Sort(400GB)：Shuffle密集型任务 Grep(600GB)：I/O密集型任务 TPC-H：I/O密集型任务 三种调度策略进行对比： Original:只考虑了数据本地化而没有考虑存储介质的差异； Storage-type：只考虑了存储介质的差异而没有考虑数据本地化； H-Scheduler：既考虑了数据本地化又考虑了存储介质的差异。 分别评估了两种job： Single job on cluster: Multiple jobs on cluster：同时运行三个job 影响H-Scheduler的三个重要参数： SSD 任务的比例：比例越高，性能越好 SSD的副本数目： SSD task，remote SSD task和HDD task之间时间的比例 七、相关研究任务调度在大数据处理平台上处理策略： 提升数据本地化程度通过提升数据本地化的程度来提升大数据平台的处理性能 处理方法 文章 通过延迟调度来获得更高的数据本地化程度 [11] 从随机网络的角度考虑map任务本地化的问题，并提出一种新的排队算法，以同时最大化吞吐量并最小化重负载条件下的延迟。 [24] 通过复制文件的方式 [12],[16] 处理异构计算资源 处理方法 文章 首次考虑异构问题并采取一种静态方法来计算任务的进度 [17] 探讨落后者/异常值的原因，并在其生命周期的早期发展原因和资源感知技术可以更智能地处理异常值。 [19] 利用历史信息来调整Map和Reduce阶段的权重，以便更准确地估计任务执行时间 [18] 使用K-means算法对历史数据进行分类，来提升对于任务阶段权重评估的准确性 [25] 使用动态负载重新平衡（更快的节点获取更多数据）来调度任务 [20],[21] document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/03/14/论文笔记03：H-Scheduler Storage-Aware Task Scheduling for Heterogeneous-Storage Spark Clusters/"},{"title":"Kafka原理分析","text":"Kafka原理分析介绍Apache Kafka是一个分布式发布-订阅消息传递系统，最初由LinkedIn公司开发，后于2010年贡献给Apache 基金会并成为顶级开源项目。它是一个分布式的、可划分的、冗余备份的持久性的日志服务，主要用于处理活跃的流式数据。其架构如下图所示： Kafka的工作流程大致如下： 生产者会根据业务逻辑产生消息，之后根据路由规则将消息发送到指定分区的Leader副本所在的Broker上。在Kafka服务端接收到消息后，会将消息追加到Log中保存，之后Follower副本会与Leader副本进行同步，当ISR集合中所有副本都完成了此消息的同步后，则Leader副本的HW会增加，并向生产者返回响应。 当消费者加入到Consumer Group时，会触发Rebalance操作将分区分配给不同的消费者消费。随后，消费者会恢复其消费位置，并向Kafka服务端发送拉取消息的请求，Leader副本会验证请求的offset以及其他相关信息，最后返回消息。 Kafka的一些概念Message消息是Kafka中最基本的数据单元。消息由一串字节构成，其中主要由key和value构成，key和value也都是byte数组； BrokerKafka 集群包含一个或多个服务器，这种服务器被称为 Broker； Topic主题，Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic； Partition物理上的概念，每个 Topic 包含一个或多个 Partition，每个Partition内部是有序的； 每个消息在被添加到分区时，都会被分配一个offset，它是消息在此分区中的唯一编号，Kafka通过offset保证消息在分区内的顺序，offset的顺序性不跨分区，即Kafka只保证在同一个分区内的消息是有序的；同一Topic的多个分区内的消息，Kafka并不保证其顺序性。 副本Kafka对消息进行了冗余备份，每个Partition可以有多个副本，每个副本中包含的消息是一样的。每个分区的副本集合中，都会选举出一个副本作为Leader副本，Kafka在不同的场景下会采用不同的选举策略。所有的读写请求都由选举出的Leader副本处理，其他都作为Follower副本，Follower副本仅仅是从Leader 副本处把数据拉取（pull）到本地之后，同步更新到自己的Log中。一般情况下，同一分区的多个分区会被分配到不同的Broker上，这样，当Leader所在的Broker宕机之后，可以重新选举新的Leader，继续对外提供服务。 如下图所示： ISR集合ISR（In-Sync Replica）集合表示的是目前“可用”（alive）且消息量与Leader相差不多的副本集合，这是整个副本集合的一个子集。“可用”和“相差不多”都是很模糊的描述，其实际含义是ISR集合中的副本必须满足下面两个条件： 副本所在节点必须维持着与ZooKeeper的连接； 副本最后一条消息的offset与Leader副本的最后一条消息的offset之间的差值不能超出指定的阈值。 每个分区中的Leader副本都会维护此分区的ISR集合。写请求首先由Leader副本处理，之后Follower副本会从Leader上拉取写入的消息，这个过程会有一定的延迟，导致Follower副本中保存的消息略少于Leader副本，只要未超出阈值都是可以容忍的。如果一个Follower副本出现异常，比如：宕机，发生长时间GC而导致Kafka僵死或是网络断开连接导致长时间没有拉取消息进行同步，就会违反上面的两个条件，从而被Leader副本踢出ISR集合。当Follower副本从异常中恢复之后，会继续与Leader副本进行同步，当Follower副本“追上”（即最后一条消息的offset的差值小于指定阈值）Leader副本的时候，此Follower副本会被Leader副本重新加入到ISR中。 HWHW（HighWatermark）标记了一个特殊的offset，当消费者处理消息的时候，只能拉取到HW之前的消息，HW之后的消息对消费者来说是不可见的。与ISR集合类似，HW也是由Leader副本管理的。当ISR集合中全部的Follower副本都拉取HW指定消息进行同步后，Leader副本会递增HW的值。Kafka官方网站将HW之前的消息的状态称为“commit”，其含义是这些消息在多个副本中同时存在，即使此时Leader副本损坏，也不会出现数据丢失。 LEOLEO（Log End Offset）是所有的副本都会有的一个offset标记，它指向追加到当前副本的最后一个消息的offset。当生产者向Leader副本追加消息的时候，Leader副本的LEO标记会递增；当Follower副本成功从Leader副本拉取消息并更新到本地的时候，Follower副本的LEO就会增加。下图展示了针对offset为11的消息，ISR集合、HW与LEO是如何协调工作的： ①Producer向此Partition推送消息。②Leader副本将消息追加到Log中，并递增其LEO。③Follower副本从Leader副本拉取消息进行同步。④Follower副本将拉取到的消息更新到本地Log中，并递增其LEO。⑤当ISR集合中所有副本都完成了对offset=11的消息的同步，Leader副本会递增HW。 在①~⑤步完成之后，offset=11的消息就对生产者可见了。 Kafka权衡了同步复制和异步复制两种策略，通过引入了ISR集合，巧妙地解决了上面两种复制策略存在的缺陷： 当Follower副本的延迟过高时，Leader副本被踢出ISR集合，消息依然可以快速提交，生产者可以快速得到响应，避免高延时的Follower副本影响整个Kafka集群的性能。 当Leader副本所在的Broker突然宕机的时候，会优先将ISR集合中Follower副本选举为Leader副本，新的Leader副本中包含了HW之前的全部消息，这就避免了消息的丢失。值得注意是，Follower副本可以批量地从Leader副本复制消息，这就加快了网络I/O，Follower 副本在更新消息时是批量写磁盘，加速了磁盘的I/O，极大减少了Follower与Leader的差距。 Producer消息生产者，向Broker发送消息的客户端；生产者（Producer）的主要工作是生产消息，并将消息按照一定的规则推送（push）到Topic的分区中。这里选择分区的“规则”可以有很多种，例如：根据消息的key的Hash值选择分区，或按序轮询（Round-robin）全部分区的方式。 Consumer消息消费者，从Broker读取消息的客户端；消费者（Consumer）的主要工作是从Topic中拉取消息，并对消息进行消费。某个消费者消费到Partition的哪个位置（offset）的相关信息，是Consumer自己维护的。 这样设计非常巧妙，避免了Kafka Server端维护消费者消费位置的开销，尤其是在消费数量较多的情况下。另一方面，如果是由Kafka Server端管理每个Consumer消费状态，一旦Kafka Server端出现延时或是消费状态丢失，将会影响大量的Consumer。同时，这一设计也提高了Consumer的灵活性，Consumer可以按照自己需要的顺序和模式拉取消息进行消费。例如：Consumer可以通过修改其消费的位置实现针对某些特殊key的消息进行反复消费，或是跳过某些消息的需求。 Consumer Group在Kafka中，多个Consumer可以组成一个Consumer Group，一个Consumer只能属于一个Consumer Group。Consumer Group保证其订阅的Topic的每个分区只被分配给此Consumer Group中的一个消费者处理。如果不同Consumer Group订阅了同一Topic，Consumer Group彼此之间不会干扰。这样，如果要实现一个消息可以被多个消费者同时消费（“广播”）的效果，则将每个消费者放入单独的一个Consumer Group；如果要实现一个消息只被一个消费者消费（“独占”）的效果，则将所有的Consumer放入一个Consumer Group中。 注意，Consumer Group中消费者的数量并不是越多越好，当其中消费者数量超过分区的数量时，会导致有消费者分配不到分区，从而造成消费者的浪费。 特性 高吞吐量、低延迟：Kafka每秒可以处理几十万条消息，而它的延迟最低只有几毫秒； 可拓展性：Kafka集群支持热拓展； 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失； 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）； 高并发：支持数千个客户端同时读写 参考资料 《Apache Kafka源码剖析》 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/03/05/Kafka原理分析/"},{"title":"《大型网站技术架构》读书笔记——第1篇 概述","text":"1. 大型网站架构演化1.1 大型网站软件系统的特点 高并发、大流量 高可用 海量数据 用户分布广泛，网络情况复杂 安全环境恶劣 需求快速变更，发布频繁 渐进式发展 1.2 大型网站架构演化发展历程 初始阶段，应用程序、数据库、文件等资源都在同一台服务器上，通常是LPAM（Linux，PHP，Apache，MySQL）。 应用服务和数据服务分离，随着业务的发展一台服务器已经不能满足需求了，这时候就将数据服务分离出来了。 使用缓存改善网站性能，通常网站的访问遵循二八定律，大部分的业务访问集中在小部分数据上，那么缓存这部分数据就可以减轻服务器的压力，从而提高访问速度。缓存分为两种：本地缓存和远程分布式缓存。 使用应用服务器集群改善网站的并发处理能力，应用服务器利用集群来实现网站的可伸缩性，一般通过负载均衡调度服务器来将集群中加入更多的应用服务器。 数据库的读写分离，使用缓存并不能满足更多的用户规模，数据库会因为负载过大成为网站性能的瓶颈。目前主流的数据库都提供主从热备功能，通过主从复制来实现数据库的读写分离。 使用反向代理和CDN加速网站响应，反向代理和CDN的原理都是缓存，区别在于CDN部署在网络提供商的机房，根据地理位置来获取数据；而反向代理则部署在网站的中心机房，当请求达到中心机房的时候首先访问反向代理。 使用分布式文件系统和分布式数据系统，随着业务需求的持续增长，文件系统也不能满足需求了。分布式数据库是网站数据库拆分的最后手段，只能有不得已的情况下，才将大表拆分，通常的手段是业务分库，即将不同业务的数据部署在不同的物理机上。 使用NoSQL和搜索引擎，对于数据存储和检索的需求越发复杂，NoSQL和搜索引擎有着更好的可伸缩的分布式特性。 业务拆分，对了应对日益复杂的业务场景，通过分而治之的手段，将整个网站业务拆分成不同的产品线，分别由不同的业务团队负责。应用之间可以通过一个超链接建立关系，还可以使用消息队列进行数据分发，最多的是通过访问同一个数据存储系统来构成一个关联的完整系统。 分布式服务，随着业务拆分越来越小，部署维护难度增大。既然每一个应用系统都需要执行许多相同的操作，那么可以将这些共有的业务提取出来，独立部署。 2. 大型网站架构模式模式，来自建筑学的定义“每一个模式描述了一个在我们周围不断重复发生的问题及该问题解决方案的核心。这样，你就能一次又一次地使用该方案而不必做重复工作”。关键在于问题和场景的可重复性带来的解决方案的可重复性。 2.1 网站架构模式 分层：通过分层，可以将一个庞大的系统分成不同的部分，便于分工合作与维护；各层之间具有一定的独立性，只要维护调用接口不变，各层可以根据具体问题具体分析。分层通常都是逻辑上的，部署上可以在同一台物理机上也可以分离部署。 分割：分割是对软件的纵向切分，将不同的功能和服务分割开，有助于开发和维护也提高了网站的并发处理能力和功能拓展性。例如，在应用层对不同业务进行分割，分成购物、论坛、搜索、广告等。 分布式：分层和分割都是为了方便分布式部署，即将不同模块部署在不同的服务器上，通过远程调用协作。分布式同样带来一些问题，网络对于性能的影响，服务器宕机的威胁，数据一致性等问题。常用的分布式方案有： 分布式应用和服务：将分层和分割后的应用按照模块分布式部署； 分布式静态资源：动静分离的策略，减轻服务器负载和加快加载速度； 分布式数据和存储：海量数据，单个机器已经无法存储，只有利用分布式存储； 分布式计算：加快数据处理的速度 集群：多台服务器部署相同应用构成一个集群，通过负载均衡设备共同对外提供服务； 缓存：将数据存放在距离计算最近的位置以加快处理速度，缓存是改善软件性能的第一手段。 CDN：内容分发网络，部署在距离客户端最近的网络服务商，用户的网络请求总是先到达他的网络服务商那里，在这里缓存网站的一些静态资源。 反向代理：属于网站前端架构的一部分，部署在网站的前端，当用户请求达到网络的数据中心的时候，最先访问反向代理，这里会缓存网站的静态资源。 本地缓存：应用服务器本地缓存着一些热点数据，直接可以在本机内存中访问数据，无需访问数据库。 分布式缓存：缓存所需的空间太大，单机不能承受，会存放在一个专门的分布式缓存集群。 异步：通过异步来给系统解耦，异步构架是典型的生产者-消费者模式。 冗余：为了应对服务器的宕机，应当保持服务器的一定冗余，实现高可用。数据库利用定期备份存档，实现冷备份；利用主从分离，实现热备份。 自动化：目前主要集中在发布运维方面 安全：通过密码和手机验证码进行身份认证；登录、交易等操作需要对网络通信进行加密；为了防止机器人程序滥用网络资源攻击网站，使用验证码识别；对于XSS攻击、SQL注入等常见攻击进行相应处理；对交易转账等重要操作根据交易模式和交易信息进行风险控制。 3. 大型网站核心架构要素架构，即“最高层次的规划，难以改变的决定”。 软件架构，即“有关软件整体结构与组件的抽象描述，用于指导大型软件系统各个方面的设计”。系统的各个重要部分及其关系构成了系统的架构，这些组成部分可以是具体的功能模块，也可以是非功能的设计与决策，它们相关的关系组成一个整体，共同构成了软件系统的架构。 系统架构需要关注性能、可用性、伸缩性、扩展性和安全性这5个架构要素来衡量一个软件架构设计的优劣。 3.1 性能优化网站性能的手段非常多，从用户浏览器到数据库，影响用户请求的所有环节都可以进行性能优化。 在浏览器端，可以通过浏览器缓存、使用页面压缩、合理布局页面、减少Cookie传输等改善性能。 在应用服务器端，可以使用服务器本地缓存和分布式缓存，通过缓存在内存中的热点数据处理用户请求，加快请求处理过程，降低数据库负载。 可使用CDN，将网站静态内容分发到离用户最近的网络服务商机房；在网站机房部署反向代理服务器，缓存热点数据，加快请求响应速度，减轻数据库压力。 可通过异步操作将用户请求发送至消息队列后直接返回响应给用户。 可以将多台应用服务器组成一个集群共同对外服务，提高整体处理能力，优化性能。 在代码层面，使用多线程、改善内存管理等手段优化性能。 在数据库上，使用索引、缓存、SQL优化等改善性能。 衡量性能有一系列指标，重要的有响应时间、TPS、系统性能计数器等。 3.2 可用性高可用设计的目标是当服务器宕机的时候，服务或者应用依然可用。 主要手段是冗余，对于应用服务器来说，任何一台机器宕机，通过负载均衡都可以将请求切换到其他服务器上实现高可用，前提条件是在应用服务器上不能保存请求的会话信息。 对于存储服务器来说，需要对数据进行实时备份，当服务器宕机的时候切换服务器进行数据恢复可以保证宕机时候的数据依然可用。 网站的高可用还需要软件开发过程的质量保证。通过预发布验证、自动化测试、自动化发布、灰度发布等手段，减少将故障引入线上环境的可能。 衡量高可用的标准是，假设系统中任何一台或多台服务器宕机以及各种不可预期的问题的时候，系统整体是否依然可用。 3.3 伸缩性伸缩性，即通过不断向集群加入服务器的手段来环节不断上身用户并发访问压力和不断增长的数据存储需求。 对于应用服务器集群，只要服务器上不保存数据，所以服务器都是对等的，通过使用合适的负载均衡设备就可以向集群中不断加入服务器。 对于缓存服务器集群，加入新的服务器可能会导致缓存路由失效，进而导致集群中大部分缓存数据都无法访问。需要改进缓存路由算法来保证缓存数据的可访问性。 关系型数据难以做到大规模集群的可伸缩性，一般通过路由分区等手段将部署有多个数据库的服务器组成一个集群。 3.4 扩展性扩展性是直接关注网站的功能需求，主要标准是在网站增加新的业务产品时，是否可以实现对现有产品透明无影响，不需要任何改动或者很少改动既有业务功能就可以上线新产品。 主要手段是事件驱动构架和分布式服务。事件驱动架构通常由消息队列实现，将用户和其他业务事件造成的消息发布到消息队列，消息的处理者作为消费者从消息队列中获取消息进行处理。通过这种方式将消息的产生和处理分离，可以透明地增加新消息的生产者或者新消息的消费者。 分布式服务则是由将业务和可复用服务分离开，通过分布式服务框架调用。新增产品可以通过调用复用的服务实现自身的业务逻辑；可复用服务升级变更后，也可以通过提供多版本服务对应用实现透明升级。 通常大型网站会吸引第三方开发者，调用网站服务，其主要途径就是大型网站提供的开放平台接口。 3.5 安全性安全性，即保护网站不受恶意访问和攻击，保护网站的重要数据不被窃取。 其衡量标准就是针对现存和潜在的各种攻击与窃密手段，是否有可靠的应对策略。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/03/24/《大型网站技术架构》读书笔记00/"},{"title":"Redis常见面试题总结","text":"1. Redis为什么这么快？ 完全基于内存，绝大部分请求是纯粹的内存操作，执行效率非常高。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的； 采用单线程（该单线程指的是处理网络请求的线程），避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 使用多路I/O复用模型，非阻塞IO； 2. Redis中常用数据类型查看详细 3. 从海量Key里查询出某一固定前缀的Key留意细节： 摸清数据规模，即问清楚边界； 使用keys指令来扫出指定模式的key列表， 使用keys对线上的业务的影响：KEYS pattern：查找所有符合给定模式pattern的key 缺点： KEYS指令一次性返回所有匹配的key； 键的数量过大会使得服务卡顿； 这时可以使用SCAN指令： SCAN cursor [MATCH pattern] [COUNT count] 基于游标的迭代器，需要基于上一次的游标延续之前的迭代过程； 以0作为游标开始一次新的迭代，直到命令返回游标0完成一次遍历； 不保证每次执行都返回某个给定数量的元素，支持模糊查询； 对于增量式迭代命令，一次返回的数量不可控，只能是大概率符合count参数； 1&gt;scan 0 match k1* count 10 4. 如何通过Redis实现分布式锁分布式锁需要解决的问题： 互斥性 安全性 死锁：一个持有锁的客户端宕机而导致其他客户端再也无法获得锁，从而导致的死锁； 容错 如何实现： SETNX（Set if not exsist） key value：如果key不存在，则创建并赋值。因为SETNX有上述功能，并且操作都是原子的，因此在初期的时候可以用来实现分布式锁。 时间复杂度：O(1) 返回值：设置成功，返回1，表明此时没有其他线程占用该资源；设置失败，返回0，表示此时有别的线程正在占用该资源。 使用EXPIRE key seconds来解决SETNX长期有效的问题： 设置key的生存时间，当key过期时（生存时间为0），会被自动删除； 12345678RedisService redisService = SpringUtils.getBean(RedisService.class);long status = redisService.setnx(key,&quot;1&quot;);if(status == 1){ redisService.expire(key,expire); //执行独占资源逻辑 doOcuppiedWork();} 以上方法的缺点：原子性无法得到满足 从Redis 2.1.6 以后，原子操作set： SET key value [EX seconds] [PX milliseconds] [NX|XX] EX seconds：设置键的过期时间为second（秒） PX milliseconds：设置键的过期时间为millisecond（毫秒） NX：只在键不存在的时候，才对键进行设置操作，效果等同于setnx XX：只在键已存在的时候，才对键进行设置操作 SET操作成功完成时，返回OK，否则则返回nil 1234&gt; set lock 123 ex 10 nxOK&gt; set lock 122 ex 10 nx(nil) 代码实现例如： 1234567RedisService redisService = SpringUtils.getBean(RedisService.class);String result = redisService.set(lockKey,requestId,SET_IF_NOT_EXIST, SET_WITH_WITH_EXPIRE_TIME,expireTime);if(&quot;OK&quot;.equals(result)){ //执行独占资源逻辑 doOcuppiedWork();} 大量key同时过期的注意事项： 集中过期，由于清楚大量key很耗时，会出现短暂的卡顿现象。 解决方法：在设置key的过期时间的时候，给每个key加上一个随机值。 5. 如何使用Redis做异步队列使用List作为队列，RPUSH生产消息，LPOP消费消息。 缺点：没有等待队列中有值就直接消费； 弥补：可以在应用层引入Sleep机制去调用LPOP重试 BLPOP key [key …] timeout：阻塞直到队列有消息就能够返回或超时 缺点：只能供一个消费者消费 pub/sub：主题发布-订阅模式 发送者（publish）发送消息，订阅者（subscribe）接收消息； 订阅者可以订阅任意数量的频道（Topic）； 缺点：消息的发布是无状态的，无法保证可达性，即发送完该消息无法保证该消息被接收到。若想解决该问题需要使用专业的消息队列，例如Kafka等。 6. Redis如何做持久化Redis有三种持久化的方式： RDB(快照)持久化：保存某个时间点的全量数据快照； 缺点： 内存数据的全量同步，数据量大会由于I/O而严重影响性能； 可能会因为Redis挂掉而丢失从当前至最近一次快照期间的数据； redis.conf文件中： 1234567save 900 1 #900秒之内如果有1条写入指令就触发一次快照save 300 10save 60 10000stop-writes-on-bgsave-error yes #表示备份进程出错的时候，主进程就停止接收新的写入操作，是为了保护持久化数据的一致性rdbcompression no #RDB的压缩设置为no，因为压缩会占用更多的CPU资源 手动触发： SAVE：阻塞Redis的服务器进程，知道RDB文件被创建完毕，很少被使用； BGSAVE：Fork出一个子进程来创建RDB文件，不会阻塞服务器主进程。 自动触发： 根据redis.conf配置里的Save m n 定时触发（用的是BGSAVE） 主从复制，主节点自动触发。从节点全量复制时，主节点发送RDB文件给从节点完成复制操作，主节点这时候会触发BGSAVE； 执行Debug Reload； 执行Shutdown且没有开启AOF持久化 BGSAVE原理： 检查子进程的目的是：为了防止子进程之间的竞争； 系统（Linux）调用fork()：创建进程，实现Copy-on-write（写时复制）。传统方式下，在fork进程时直接把所有资源全部复制给子进程，这种实现方式简单但是效率低下。Linux为了降低创建子进程的成本，改进fork实现，当父进程创建子进程时，内核只为子进程创建虚拟空间，父子两个进程使用的是相同的物理空间，只有子进程发生更改的时候，才会为子进程分配独立的物理空间。 Copy-on-write： 如果有多个调用者同时要求相同资源(如内存或磁盘上的数据存储)，他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本给该调用者，而其他调用者所见到的最初的资源仍然保持不变。 AOF(Append-Only-File)持久化：保持写状态 记录下除了查询以外的所有变更数据库状态的指令，所有写入AOF的指令都是以Redis协议格式来保存的； 以append的形式追加保存到AOF文件中（增量），就算遇到停电的情况也能尽最大全力去保证数据的无损； 日志重写解决AOF文件大小不断增大的问题，原理如下： 调用fork()，创建一个子进程； 子进程把新的AOF写到一个临时文件里面，不依赖于原来的AOF文件； 主进程持续将新的变动同时写到内存buffer中和原来的AOF文件里； 主进程获取子进程重写AOF的完成信号，往新的AOF文件同步增量变动； 使用新的AOF文件替换旧的AOF文件 对于上图有几个关键点： 在重写期间，由于主进程依然在响应命令，为了保证最终备份的完整性。因此它依然会写入旧的AOF file中，如果重写失败，能够保证数据不丢失。 为了把重写期间响应的写入信息也写入到新的文件中，因此也会为子进程保留一个buf，防止新写的file丢失数据。 重写是直接把当前内存的数据生成对应命令，并不需要读取老的AOF文件进行分析、命令合并。 AOF文件直接采用的文本协议，主要是兼容性好、追加方便、可读性高。 RDB和AOF文件共存情况下的恢复流程 RDB和AOF的优缺点： 类别 优点 缺点 RDB 全量数据快照，文件小，恢复快 无法保存最近一次快照之后的数据，会丢失这部分的数据 AOF 可读性高，适合保存增量数据，数据不易丢失 文件体积大，恢复时间长 RDB-AOF混合持久化方式 在Redis 4.0之后推出了混合持久化方式，而且作为默认的配置方式。先以RDB方式从管道写全量数据再使用AOF方式从管道追加。AOF文件先半段是RDB形式的全量数据，后半段是Redis命令形式的增量数据。 BGSAVE做镜像全量持久化，AOF做增量持久化。因为BGSAVE需要耗费大量的时间，不够实时，在停机的时候会造成大量数据丢失，这时需要AOF配合使用。在Redis实例重启的时候，会使用BGSAVE持久化文件重新构建内容，再使用AOF重放近期的操作指令，来实现完整恢复重启之前的状态。 7. 使用Pineline的好处 Pineline和Linux的管道类似； Redis基于请求/响应模型，单个请求处理需要一一应答； Pineline批量执行指令，节省了多次I/O往返的时间； 有顺序依赖的指令建议分批发送； Redis的同步机制：主从同步原理 通常Redis的主从模式中，使用一个Master进行写操作，若干个Slave进行读操作。定期的数据备份操作是选择一个Slave进行的，这样能够最大程度上发挥Redis的性能，为了支持数据的弱一致性，即数据的最终一致性，不需要保持Master和Slave之间数据每个时刻都是相同的，但是在过了一段时间后它们之间的数据是趋于同步的。Redis可以使用主从同步，也可以使用从从同步。 全同步过程： Slave发送sync命令到Master； Master启动一个后台进程，将Redis中的数据快照保存到文件中（BGSAVE）； Master将保存数据快照期间接收到的写命令（增量数据）缓存起来； Master完成写文件操作后，将该文件发送给Slave； Slave接收到文件之后，使用新的AOF文件替换掉旧的AOF文件来，从磁盘上读到内存中，来恢复数据快照； Master将这期间收集的增量写命令发送给Slave端，进行重放。 全同步完成后，后续所有写操作都是在Master上进行，读操作都是在Slave上进行。 增量同步过程： Master接收到用户的操作指令，判断是否需要传播到Slave，如果需要则进行下一步； 首先将操作转换成Redis内部协议格式并以字符串的形式存储，然后将字符串存储的操作纪录追加到AOF文件； 将操作传播到其他Slave：1. 对齐主从库，确保从数据库的该操作的数据库；2. 将命令和参数按照Redis内部协议格式往响应缓存中写入指令； 将缓存中的数据发送给Slave。 主从模式的弊端在于不具有高可用性，当Master挂掉以后，Redis将不能对外提供写入操作。 Redis Sentinel（Redis哨兵） 解决主从同步Master宕机后的主从切换问题： 监控：检查主从服务器是否运行正常； 提醒：通过API向管理员或者其他应用程序发送故障通知； 自动故障迁移：主从切换； 流言协议Gossip 在杂乱无章中寻求一致 每个节点都随机地与对方通信，最终所有节点的状态都会达到一致； 种子节点定期（每秒）随机向其他节点发送节点列表以及需要传播的消息； 不保证信息一定会传递给所有节点，但是最终会趋于一致。 8. Redis的集群原理如何从海量数据里快速找到所需？ 分片：按照某种规则去划分数据，分散存储在多个节点上； 常规的按照哈希划分无法实现节点的动态增减，为了解决这个问题引入了一致性哈希算法。 一致性哈希算法：对2^32取模，将哈希值空间组织成虚拟的圆环，hash空间的范围为[0,2^32-1]如下图所示： 将数据key使用相同的函数Hash计算出哈希值，具体可以选择服务器的ip或主机名作为关键字进行hash，这样就能确定每个服务器在Hash环上的位置。接下来，将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的目标服务器。根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。 现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响，如下所示： 下面考虑另外一种情况，如果在系统中增加一台服务器Node X，如下图所示： 此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X ！一般的，在一致性Hash算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。 综上所述，一致性哈希算法对于节点的增减都只需要定位环空间中的一小部分数据，具有较好的容错性和扩展性。 补充资料：https://zhuanlan.zhihu.com/p/34985026 缺点：一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下： 解决方法：引入虚拟节点，即对每个服务器节点计算多个hash，计算结果的位置都放置一个节点称为虚拟节点。具体做法，例如在服务器ip或主机名后添加序号。 参考资料 https://coding.imooc.com/class/303.html https://zhuanlan.zhihu.com/p/34985026 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/05/23/redis/"},{"title":"论文笔记04：A Heterogeneity-Aware Task Scheduler for Spark","text":"论文笔记04：A Heterogeneity-Aware Task Scheduler for Spark发表于2018 一、解决的问题大数据平台的应用没有关注到多维度的异构场景，导致在调度资源的时候，应用和硬件特性之间存在着本质上的不匹配问题。 二、提出的方法2.1 创新点提出了一种异构感知的任务调度系统——RUPAM，同时考虑任务级别的资源特征和硬件层面的特征，还能够保持数据本地化。RUPAM使用一种简单但高效的启发式去决定主导型的调度因素，将一个任务放置到特定的stage上。 2.2 结果RUPAM对于Spark标准的调度器来说提升了62.3%的性能 三、背景Spark调度当前的Spark分为两个级别的调度： 应用级别调度：通常使用一些集群管理器来实现，例如内置的standalone集群管理器和外部的Mesos、YARN等，这些管理器通常会抽象硬件属性为CPU核数和内存大小。最主要的局限性体现在这些资源管理器不能够动态地满足应用的需求。 任务级别调度：当前的任务调度器只是将一个任务分配给一个CPU的核上，只考虑了数据本地化的因素。现有的异构性感知调度程序仅关注底层节点的异构性，并且通常假设同一Map / Reduce阶段中的所有任务具有相同的特征，如我们所示，并不总是成立。 前置研究为了评估当前Spark的调度器，进行了了一些实验，通过这些实验得到的结论： 在单个应用上的不同stage的资源利用率是不同的：当前Spark调度器只是静态地将CPU核和存储器的一部分分配给给定应用程序（如当前调度程序中的情况）而没有考虑所需资源中的这种多样性和不一致性。 单个stage存在任务偏差：当前异构感知调度器假设同一个stage上任务有着相似的特征，表现性能也是相同的。 这些实验表明，即使在应用程序生命周期内，Spark应用程序也可能需要不同的资源， 其中的任务也具有不同的特征。 四、设计A. 系统架构RUPAM是一种任务级别的调度器，与应用级别和作业级别的调度器一起工作。 Resource Monitor(RM)：资源监控器，负责系统资源的实时监控。它有一个运行在Spark的Master和Worker的监视器，收集器报告每个节点上资源的使用情况，例如CPU、内存、网络、I/O和GPU等。监视器负责从这些节点上收集和记录这些信息。还能够拓展收集资源性能上的更多信息。 Task Manager (TM)：任务管理器，跟踪任务资源使用情况以确定任务的任何资源瓶颈。 Dispatcher：实现RUPAM的主要逻辑，例如决定启动每个节点上executor的大小，将每个任务匹配合适的节点，对于特定节点启动任务的数量，基于多个维度调度任务。 利用TM和Dispatcher来取代Spark内置的TaskScheduler，不单单考虑数据本地化，而是同时考虑任务和节点的资源特性来调度任务。 B. 实时资源监控和任务监控对于同一个任务的运行每个阶段的瓶颈期可能是不一样的，这样在任务整个生命周期上跟踪节点的资源使用情况为了低延迟来决定将任务分配到最优的节点上进行执行。 资源监控： RUPAM利用心跳机制周期性地获取更多维度的硬件信息，使用一个对每个类型资源的优先队列。RUPAM只需要将节点中的一小部分进行排序，并且在下一轮调度的时候清空队列。通过这样的方式，能够保持较小的队列来降低排序过程的时间复杂度。 任务监控： 为了给定的节点选择一个合适的任务，RUPAM也需要根据任务的特性来进行决策。RUPAM使用一个数据库来存储周期性的数据中心的任务特性。为了将分辨在同一个stage资源需求的不同，TM为每种类型的资源保持一个队列。为了解决如何管理频繁的数据库操作，RUPAM使用一个帮助线程来辅助。 C. 任务调度优化目标是：最小化对所有机器的所有任务的总执行时间 当前最流行的解决方法是列表调度算法，这是一种贪心算法，可以将任务映射到可用的机器而不会引入空闲时间。由于列表调度提供了具有良好的理论界限的实际解决方案，RUPAM采取了一种基于贪心的启发式算法。考虑的因素有： 硬件节点的容量（SSD,GPU） 每个任务的资源消耗 节点中每个资源的资源争用 运行在同一节点的任务数量 数据本地化 1. 调度策略Dispatcher在task队列和资源队列的帮助下匹配任务，在RM填充资源队列之后，RUPAM以轮询的方式一次从每个资源队列中取出一个节点，以确保没有任何单一资源类型的任务饥饿。这种启发式贪心策略找到一个具有最佳容量和最低争用资源R的节点N，然后将N调度到任务T，其中R作为其先前运行中的瓶颈，如今N为T提供了最佳位置。RUPAM没有尝试对每个任务寻找一个全局最优的调度策略，因为这样可能会造成一个比较大的调度延迟，效果可能适得其反。将任务“锁定”到提供最佳观察性能的节点上，还可以防止由于任务特征的临时波动而在节点之间来回移动任务。 2. 资源分配Spark在启动executor的时候会为其设置一个固定的CPU核数和内存，这种静态的配置其实是低效的。 首先，在异构环境下，节点拥有不同的内存大小和CPU核数； 第二，基于一个节点上的CPU核数来决定任务的slot其实是不准确的； 通过超提交一些具有空闲资源的节点和用适当的任务匹配节点，RUPAM可以重叠具有不同资源需求的任务。 3. 落后的任务（Straggler）和任务的重定位为了弥补Dispatcher可能存在的次优决策，RUPAM还与最近引入的Spark推测执行系统一起工作，以在可用节点中启动Straggler的副本。当完成的任务数量达到一个阈值（默认是总数的75%），该推测系统就会搜索那些耗时超过已完成任务平均执行时间的一个系数的任务并且将其标记为Straggler任务。Straggler的副本将会在下一个可用节点上进行计算。除了被Spark检测为标准Straggler之外，RUPAM同样也会根据异构环境检测Straggler。 为了避免JVM中的OOM异常，RUPAM还采取了一种激进地策略检测内存的straggler。首先，只要RM检测到一个节点的可用内存较低的时候，它就发送消息给TM，并且通过检测当前正在运行的任务，TM标记那些占用较多内存的任务为Straggler，并终止这些任务。在标记之后，将这些任务的副本发送到TM，TM会根据这些任务的特性来确定其瓶颈并且将其再次放入任务队列。Dispatcher又可以再次将这些任务分配到适合的闲置节点上。 五、目标和设定设定每台机器上处理任务的时间根据机器变化 优化目标最小化最大完工时间 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/03/19/论文笔记04：A Heterogeneity-Aware Task Scheduler for Spark/"},{"title":"论文笔记05：SABA A security-aware and budget-aware workflow scheduling strategy in clouds","text":"论文笔记05：SABA A security-aware and budget-aware workflow scheduling strategy in clouds发表于2014.7 一、解决的问题对于云环境下工作流的应用调度策略中，解决当前研究中忽视的带有安全要求和例如像内存，存储介质容量这些其他硬件资源的问题。 二、提出的方法2.1 创新点由于考虑了安全和花费提出了“不可移动数据集”的概念用来约束某些数据集的移动，基于这个概念，提出在了一种安全感知和预算感知的工作流调度策略，为用户提供更加端的完工时间和同样安全的云服务。 2.2 主要贡献 提出了SABA算法，在给定预算下在保证安全的基础上提供给用户更短的完工时间； 在安全约束下拓展了多维度的计算资源的考虑，例如网络带宽、内存、存储等； 提出了“不可移动数据集”的概念 三、相关研究现有研究不能应用到带有安全约束的在云环境下的工作流应用的三点原因： 资源竞争可能会对提交任务及其所需安全服务的计算时间和金钱成本的影响比较大； 现有研究考虑的所有数据都是可移动的； 现有云服务提供商都是共享基础资源的，与未知租户共享基础架构可能是某些工作流应用程序的主要风险，并且需要高度保证与逻辑分离的安全机制的强度。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/03/19/论文笔记05：SABA A security-aware and budget-aware workflow scheduling strategy in clouds/"},{"title":"论文笔记02：Comparative Analysis of Energy-Efficient Scheduling Algorithms for Big Data Applications","text":"发表于2018.7 一、解决的问题Spark集群在反网络犯罪中的能耗问题 二、提出的方法2.1 创新点为了避免服务级别协议违反执行时间，提出了一种最优的任务调度算法，其具有通过权衡执行时间和能量消耗的最后期限约束，目的是去最小化大数据处理中的能耗问题。该最优算法能够找到接近最优的任务调度，以在小的shuffle分区中权衡消耗的能量和响应时间的优势。 2.2 结果对比Spark内嵌的FIFO和FAIR算法，能耗上都有优化。 三、动机 对于数据中心，不需要一味降低任务的执行时间。而在是截止完成时间之前，只需要提供按需的服务，更多的关心是能耗上的优化。 四、相关工作 考虑的主要因素 文章 方法 云计算当中优化物理机上的能耗问题 — [14] 提出了考虑CPU,磁盘，内存，网络对于刀片服务器的能耗模型 — [16] 提出了考虑CPU,磁盘，内存，网络，风扇对所有服务器的能耗的直接测量 Spark调度中主要考虑的是最小化工作执行的完工时间 — [6] 他们模拟了执行器的应用程序成本和完成时间，因此提供了细粒度的资源分配方案 — [19] 通过收集在同一个应用下的不同stage执行时间来预测应用的执行时间 — [20] 提出了基于输入数据量，底层集群节点的大小和迭代次数的作业完成时间模型。 — [18] 为了预测具有未知群集配置的大数据应用程序的执行时间，提出基于应用简档数据构建多个多项式回归模型 — [21] 为Spark在线分析提供QoS保证，提出了基于熵在线并行分析调度 应对上述三个挑战的三种应对策略： Spark的executors为了及时满足它们资源预留应将被放置到合适的节点上，避免太长时间的等待和低资源利用率； 分配用于减少任务的资源应根据其随时间变化的需求进行重新平衡，以避免在将任何Spark应用程序提交到群集时浪费资源； 在考虑Spark和MapReduce应用程序的位置感知的时候,为了减少局部性感知的竞争,Spark和MapReduce应用程序的任务分配策略都应该优化。 五、算法算法1 适合的两个场景： 工作量是计算密集型的，任务数量很大； 能耗低要求较高，对于SLA截止时间要求较低。 算法2算法B权衡能耗和执行时间，特别对于小shuffle的分区的情况下。 在小分区的情况下，算法B将任务分配给集群中最佳的一半执行程序，并尝试平衡在执行程序的另一半中花费的执行时间。 算法3算法3将所有任务分成两个集合： Set0：包含所有需要被探测的任务和当前p和e为0的任务； Distribute：包含那些不需要被探测的任务。 RunTimeEachExe：记录着最优部分的执行时间 六、实验基于HiBench的基准实验，在三种工作负载上实验： Sort TeraSort PageRank 七、结果分析算法B在保证有效降低能耗的前提下，优化了算法A的执行时间。因为基于贪心策略的算法A尽可能地将任务分配给评估标准的最佳过程，导致单个节点的过载并因此导致总体执行时间的增加。 算法B使得Shuffle分区的数量从10到40变化，确保可以使用集群中一半的执行程序。因此，算法B减少了单个节点上的负载，并且还加快了作业完成时间。 算法B的两点改进： 任务分配策略 不考虑数据局部性，以确保任务可以均匀地分布到最佳的一半过程 总而言之，算法B更加适合的场景： 工作负载更少的任务 SLA的截止时间要求较高，节能要求较为宽松 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/03/14/论文笔记02：Comparative Analysis of Energy-Efficient Scheduling Algorithms for Big Data Applications/"},{"title":"论文笔记06：Security and privacy aspects in MapReduce on clouds A survey","text":"论文笔记06：Security and privacy aspects in MapReduce on clouds A survey一、介绍云计算提供三种类型的服务： IaaS； PaaS； SaaS 云计算可以分为： 公有云； 私有云； 混合云 MapReduce在最初设计的时候，并没有考虑到安全和隐私方面的问题。一个安全的MapReduce框架要解决以下几种攻击： 身份验证； 保密性（窃听和中间人攻击） 数据篡改 硬件篡改 软件篡改 安全性和隐私性之间的另外区别在于安全性更多是二元问题，即攻击成功与否，而在隐私设置中是关注于数据隐私与框架利用之间存在权衡。 二、挑战对于带有安全和隐私方面的MapReduce存在着一些挑战： 输入的数据的大小和这些数据的存储：分布式的存储带来的数据存储隐患； MapReduce计算的高度分布式特性：更多的数据副本给数据安全带来更多的隐患，在MapReduce中识别带有攻击性的mapper或者reducer不是一件容易的事情。 数据流：根据数据的敏感性来不同地处理数据，数据会在存储节点和计算节点之间移动；MapReduce的不同计算阶段可能会在不同类型的云服务上进行计算； 公有云的黑盒特性支持着MapReduce 混合云：MapReduce是设计在单一云环境下使用的，对于敏感性数据和非敏感性数据的分配增加了MapReduce使用的挑战； 可扩展性，容错机制和透明性：安全和隐私方面的机制不应该影响MapReduce的效率、拓展性、容错机制，对于用户的使用应该是透明的。 经济问题：影响MapReduce在公有云上有三种因素，分别是存储、通信代价和计算时间，安全和隐私机制的也应该经济型地加入。 不可靠的数据接入：对于MapReduce的安全和隐私算法应该应对损坏的甚至是带有攻击性的代码，保护数据，并限制带有损坏性的Mappers和Reducers的数据接入。 三、要求3.1 MapReduce的安全威胁在公有云环境下，MapReduce处理的分布式的副本数据有着很大的被攻击的可能 冒充攻击：会造成数据泄露、计算篡改和在数据上的错误计算，会造成用户在资费上的损失； 拒绝服务（DoS）攻击：Dos攻击可能会使得节点的功能失效和无法访问，可能造成集群的网络过载和框架的失效； 重放攻击：通过恶意的欺诈性地重复或拖延正常的数据传输； 窃听：在未经批准的情况下，计算结果在中间被截获； 中间人攻击：数据在传输过程中会被恶意修改、毁坏； 拒绝：当节点的mapper或者reducer被错误地拒绝处理时，会发生拒绝攻击。 3.2 MapReduce中的安全要求 Mappers和Reducers的身份验证，授权和访问控制：只有被授权的用户才能权限够处理这些mapper和reducer，对于授权的攻击是冒充攻击和重放攻击； 数据、mapper和reducer的可用性：数据、mapper和reducer对于授权的用户是没有延迟的可用性，对于这些方面的攻击对于处理时间都是有影响的； 计算和数据的保密性：为了确保机密性，在传输期间和在公共云本身上传输之后，不能拦截计算和数据。 计算和数据的完整性：计算的完整性是指公平传输（指的是从用户位置到计算位置的MapReduce计算）以及Mappers和Reducers的执行。 验证输出：验证确保了输出的完整性、正确性、及时性； 对计算和数据的核算和审核 3.3 对于MapReduce安全的对抗模型 Honest-but-curious adversary：会增加一定的额外计算； Malicious adversary：应对窃取、毁坏、修改数据，可以分为两类： non-collusive ：独立工作，不需要与其他的协作； collusive：在给出输出之前要与其他所以的一起通信； Knowledgeable adversary：具有提升安全性的能力； Network and nodes access adversary： 3.4 MapReduce安全的解决方法 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/03/19/论文笔记06：Security and privacy aspects in MapReduce on clouds A survey/"},{"title":"HTTP访问一个网站的过程详解","text":"访问一个网站的过程详解例如访问：http://www.baidu.com HTTP请求的准备浏览器会将http://www.baidu.com 这个域名发送给DNS服务器，让它解析成IP地址。由于HTTP是基于TCP协议的，先建立TCP连接，在HTTP 1.1的协议里面，默认开启了Keep-Alive,这样建立的TCP连接，就可以在多次请求中复用。 HTTP请求的发送建立TCP连接以后，通过stream二进制流的方式传给对方，到了TCP层，会将二进制流变成一个报文段发送给服务器。 在发送每个报文段的时候，都需要对方有一个回应ACK，来保证报文可靠地到达了对方。如果没有回应，那么TCP就会重新传输，直到可以到达。有时候同一个包可能被传输好多次，但这对于HTTP是透明的。 TCP层发送每一个报文的时候，都需要加上自己的地址（源地址）和它想要去的地方（目标地址），然后将源MAC和目标MAC放入MAC头，发送出去即可；若不在同一局域网内，就需要发送给网关，这时还需要发送ARP协议，来获取网关的MAC地址，然后将源MAC和网关MAC放入MAC头，发送出去。 网关收到包以后，发现MAC符合，取出目标IP，根据路由协议找到下一跳的路由器，获取下一跳路由器的MAC地址，将包发送给下一跳路由器。 这样路由器一跳一跳终于到达目标的局域网。这时候，最后一跳路由器能够发现，目标地址就在自己的某一个出口的局域网上。于是，在这个局域网上发送ARP，获得这个目标地址的MAC地址，将包发送出去。 目标机器发现MAC地址符合就将包收起来；发现IP地址符合，根据IP头中协议项，知道自己上一层是TCP协议，于是解析TCP头，里面有序列号，看一看这个序列包是不是我需要的，如果是就放入缓存中然后返回一个ACK，如果不是则丢弃。 TCP头里面还有端口号，HTTP的服务器正在监听这个端口号。于是，目标机器自然知道是 HTTP 服务器这个进程想要这个包，于是将包发给 HTTP 服务器。HTTP 服务器的进程看到，原来这个请求是要访问一个网页，于是就把这个网页发给客户端。 HTTP返回的发送根据HTTP 响应报文的格式构造好返回的HTTP报文，接下来就是把这个报文发送出去。还是交给Socket去发送，还是交给TCP层，让TCP层将返回的HTML，也分成一个个小的段，并且保证每一段都可靠到达。 这些段加上 TCP 头后会交给 IP 层，然后把刚才的发送过程反向走一遍。虽然两次不一定走相同的路径，但是逻辑过程是一样的，一直到达客户端。 客户端发现 MAC 地址符合、IP 地址符合，于是就会交给 TCP 层。根据序列号看是不是自己要的报文段，如果是，则会根据 TCP 头中的端口号，发给相应的进程。这个进程就是浏览器，浏览器作为客户端也在监听某个端口。 当浏览器拿到了 HTTP 的报文。发现返回“200”，一切正常，于是就从正文中将 HTML 拿出来。HTML 是一个标准的网页格式。浏览器只要根据这个格式，展示出一个绚丽多彩的网页。 这就是一个正常的 HTTP 请求和返回的完整过程。 参考资料 极客时间：《趣谈网络协议》 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","link":"/2019/02/24/访问一个网站的过程详解/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","link":"/tags/读书笔记/"},{"name":"《谷歌方法论》","slug":"《谷歌方法论》","link":"/tags/《谷歌方法论》/"},{"name":"HBase","slug":"HBase","link":"/tags/HBase/"},{"name":"Java并发","slug":"Java并发","link":"/tags/Java并发/"},{"name":"锁","slug":"锁","link":"/tags/锁/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"I/O多路复用","slug":"I-O多路复用","link":"/tags/I-O多路复用/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"论文笔记","slug":"论文笔记","link":"/tags/论文笔记/"},{"name":"Kafka","slug":"Kafka","link":"/tags/Kafka/"},{"name":"网站架构","slug":"网站架构","link":"/tags/网站架构/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"面试题","slug":"面试题","link":"/tags/面试题/"},{"name":"网络","slug":"网络","link":"/tags/网络/"},{"name":"HTTP","slug":"HTTP","link":"/tags/HTTP/"}],"categories":[{"name":"读书笔记","slug":"读书笔记","link":"/categories/读书笔记/"}]}